{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d723ef76-3a97-4163-8762-4f82640fd120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clearml\n",
      "  Downloading clearml-1.15.1-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: attrs>=18.0 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (23.2.0)\n",
      "Collecting furl>=2.0.0 (from clearml)\n",
      "  Downloading furl-2.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (4.22.0)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (1.24.2)\n",
      "Collecting pathlib2>=2.3.0 (from clearml)\n",
      "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: Pillow>=4.1.1 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (9.5.0)\n",
      "Requirement already satisfied: psutil>=3.4.2 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (5.9.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=3.12 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (2.31.0)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (1.26.6)\n",
      "Collecting pyjwt<2.9.0,>=2.4.0 (from clearml)\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: referencing<0.40 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from clearml) (0.35.1)\n",
      "Collecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n",
      "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema>=2.6.0->clearml) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema>=2.6.0->clearml) (0.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.20.0->clearml) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.20.0->clearml) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.20.0->clearml) (2021.5.30)\n",
      "Downloading clearml-1.15.1-py2.py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.2/1.1 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.1 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.1/1.1 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pyjwt, pathlib2, orderedmultidict, furl, clearml\n",
      "Successfully installed clearml-1.15.1 furl-2.1.3 orderedmultidict-1.0.1 pathlib2-2.3.7.post1 pyjwt-2.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c67949-113c-4239-82a2-fd601187ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clearml.automation\n",
      "clearml.automation.auto_scaler\n",
      "clearml.automation.aws_driver\n",
      "clearml.automation.cloud_driver\n",
      "clearml.automation.controller\n",
      "clearml.automation.hpbandster\n",
      "clearml.automation.job\n",
      "clearml.automation.monitor\n",
      "clearml.automation.optimization\n",
      "clearml.automation.optuna\n",
      "clearml.automation.parameters\n",
      "clearml.automation.scheduler\n",
      "clearml.automation.trigger\n",
      "clearml.backend_api\n",
      "clearml.backend_api.api_proxy\n",
      "clearml.backend_api.config\n",
      "clearml.backend_api.schema\n",
      "clearml.backend_api.schema.action\n",
      "clearml.backend_api.schema.service\n",
      "clearml.backend_api.services\n",
      "clearml.backend_api.services.v2_13\n",
      "clearml.backend_api.services.v2_13.auth\n",
      "clearml.backend_api.services.v2_13.events\n",
      "clearml.backend_api.services.v2_13.models\n",
      "clearml.backend_api.services.v2_13.organization\n",
      "clearml.backend_api.services.v2_13.projects\n",
      "clearml.backend_api.services.v2_13.queues\n",
      "clearml.backend_api.services.v2_13.tasks\n",
      "clearml.backend_api.services.v2_13.workers\n",
      "clearml.backend_api.services.v2_20\n",
      "clearml.backend_api.services.v2_20.auth\n",
      "clearml.backend_api.services.v2_20.events\n",
      "clearml.backend_api.services.v2_20.models\n",
      "clearml.backend_api.services.v2_20.organization\n",
      "clearml.backend_api.services.v2_20.pipelines\n",
      "clearml.backend_api.services.v2_20.projects\n",
      "clearml.backend_api.services.v2_20.queues\n",
      "clearml.backend_api.services.v2_20.tasks\n",
      "clearml.backend_api.services.v2_20.workers\n",
      "clearml.backend_api.services.v2_23\n",
      "clearml.backend_api.services.v2_23.auth\n",
      "clearml.backend_api.services.v2_23.events\n",
      "clearml.backend_api.services.v2_23.models\n",
      "clearml.backend_api.services.v2_23.organization\n",
      "clearml.backend_api.services.v2_23.pipelines\n",
      "clearml.backend_api.services.v2_23.projects\n",
      "clearml.backend_api.services.v2_23.queues\n",
      "clearml.backend_api.services.v2_23.tasks\n",
      "clearml.backend_api.services.v2_23.workers\n",
      "clearml.backend_api.services.v2_9\n",
      "clearml.backend_api.services.v2_9.auth\n",
      "clearml.backend_api.services.v2_9.events\n",
      "clearml.backend_api.services.v2_9.models\n",
      "clearml.backend_api.services.v2_9.organization\n",
      "clearml.backend_api.services.v2_9.projects\n",
      "clearml.backend_api.services.v2_9.queues\n",
      "clearml.backend_api.services.v2_9.tasks\n",
      "clearml.backend_api.services.v2_9.workers\n",
      "clearml.backend_api.session\n",
      "clearml.backend_api.session.apimodel\n",
      "clearml.backend_api.session.callresult\n",
      "clearml.backend_api.session.client\n",
      "clearml.backend_api.session.client.client\n",
      "clearml.backend_api.session.datamodel\n",
      "clearml.backend_api.session.defs\n",
      "clearml.backend_api.session.errors\n",
      "clearml.backend_api.session.jsonmodels\n",
      "clearml.backend_api.session.jsonmodels.builders\n",
      "clearml.backend_api.session.jsonmodels.collections\n",
      "clearml.backend_api.session.jsonmodels.errors\n",
      "clearml.backend_api.session.jsonmodels.fields\n",
      "clearml.backend_api.session.jsonmodels.models\n",
      "clearml.backend_api.session.jsonmodels.parsers\n",
      "clearml.backend_api.session.jsonmodels.utilities\n",
      "clearml.backend_api.session.jsonmodels.validators\n",
      "clearml.backend_api.session.request\n",
      "clearml.backend_api.session.response\n",
      "clearml.backend_api.session.session\n",
      "clearml.backend_api.session.token_manager\n",
      "clearml.backend_api.utils\n",
      "clearml.backend_config\n",
      "clearml.backend_config.bucket_config\n",
      "clearml.backend_config.config\n",
      "clearml.backend_config.converters\n",
      "clearml.backend_config.defs\n",
      "clearml.backend_config.entry\n",
      "clearml.backend_config.environment\n",
      "clearml.backend_config.errors\n",
      "clearml.backend_config.log\n",
      "clearml.backend_config.utils\n",
      "clearml.backend_interface\n",
      "clearml.backend_interface.base\n",
      "clearml.backend_interface.logger\n",
      "clearml.backend_interface.metrics\n",
      "clearml.backend_interface.metrics.events\n",
      "clearml.backend_interface.metrics.interface\n",
      "clearml.backend_interface.metrics.reporter\n",
      "clearml.backend_interface.model\n",
      "clearml.backend_interface.session\n",
      "clearml.backend_interface.setupuploadmixin\n",
      "clearml.backend_interface.task\n",
      "clearml.backend_interface.task.access\n",
      "clearml.backend_interface.task.args\n",
      "clearml.backend_interface.task.development\n",
      "clearml.backend_interface.task.development.stop_signal\n",
      "clearml.backend_interface.task.development.worker\n",
      "clearml.backend_interface.task.hyperparams\n",
      "clearml.backend_interface.task.log\n",
      "clearml.backend_interface.task.models\n",
      "clearml.backend_interface.task.populate\n",
      "clearml.backend_interface.task.repo\n",
      "clearml.backend_interface.task.repo.detectors\n",
      "clearml.backend_interface.task.repo.freeze\n",
      "clearml.backend_interface.task.repo.scriptinfo\n",
      "clearml.backend_interface.task.repo.util\n",
      "clearml.backend_interface.task.task\n",
      "clearml.backend_interface.util\n",
      "clearml.binding\n",
      "clearml.binding.absl_bind\n",
      "clearml.binding.args\n",
      "clearml.binding.artifacts\n",
      "clearml.binding.click_bind\n",
      "clearml.binding.environ_bind\n",
      "clearml.binding.fire_bind\n",
      "clearml.binding.frameworks\n",
      "clearml.binding.frameworks.base_bind\n",
      "clearml.binding.frameworks.catboost_bind\n",
      "clearml.binding.frameworks.fastai_bind\n",
      "clearml.binding.frameworks.lightgbm_bind\n",
      "clearml.binding.frameworks.megengine_bind\n",
      "clearml.binding.frameworks.pytorch_bind\n",
      "clearml.binding.frameworks.tensorflow_bind\n",
      "clearml.binding.frameworks.xgboost_bind\n",
      "clearml.binding.gradio_bind\n",
      "clearml.binding.hydra_bind\n",
      "clearml.binding.import_bind\n",
      "clearml.binding.joblib_bind\n",
      "clearml.binding.jsonargs_bind\n",
      "clearml.binding.matplotlib_bind\n",
      "clearml.cli\n",
      "clearml.cli.config\n",
      "clearml.cli.config.__main__\n",
      "clearml.cli.data\n",
      "clearml.cli.data.__main__\n",
      "clearml.cli.hpo\n",
      "clearml.cli.hpo.__main__\n",
      "clearml.cli.task\n",
      "clearml.cli.task.__main__\n",
      "clearml.config\n",
      "clearml.config.cache\n",
      "clearml.config.default\n",
      "clearml.config.defs\n",
      "clearml.config.remote\n",
      "clearml.datasets\n",
      "clearml.datasets.dataset\n",
      "clearml.debugging\n",
      "clearml.debugging.log\n",
      "clearml.debugging.timer\n",
      "clearml.debugging.trace\n",
      "clearml.errors\n",
      "clearml.external\n",
      "clearml.external.kerastuner\n",
      "clearml.logger\n",
      "clearml.model\n",
      "clearml.storage\n",
      "clearml.storage.cache\n",
      "clearml.storage.callbacks\n",
      "clearml.storage.helper\n",
      "clearml.storage.manager\n",
      "clearml.storage.util\n",
      "clearml.task\n",
      "clearml.task_parameters\n",
      "clearml.utilities\n",
      "clearml.utilities.async_manager\n",
      "clearml.utilities.attrs\n",
      "clearml.utilities.check_updates\n",
      "clearml.utilities.config\n",
      "clearml.utilities.deferred\n",
      "clearml.utilities.dicts\n",
      "clearml.utilities.distutils_version\n",
      "clearml.utilities.enum\n",
      "clearml.utilities.files\n",
      "clearml.utilities.gpu\n",
      "clearml.utilities.gpu.gpustat\n",
      "clearml.utilities.gpu.pynvml\n",
      "clearml.utilities.io_manager\n",
      "clearml.utilities.locks\n",
      "clearml.utilities.locks.constants\n",
      "clearml.utilities.locks.exceptions\n",
      "clearml.utilities.locks.portalocker\n",
      "clearml.utilities.locks.utils\n",
      "clearml.utilities.lowlevel\n",
      "clearml.utilities.lowlevel.astor_unparse\n",
      "clearml.utilities.lowlevel.distributed\n",
      "clearml.utilities.lowlevel.file_access\n",
      "clearml.utilities.lowlevel.threads\n",
      "clearml.utilities.matching\n",
      "clearml.utilities.networking\n",
      "clearml.utilities.parallel\n",
      "clearml.utilities.pigar\n",
      "clearml.utilities.pigar.__main__\n",
      "clearml.utilities.pigar.log\n",
      "clearml.utilities.pigar.modules\n",
      "clearml.utilities.pigar.reqs\n",
      "clearml.utilities.pigar.unpack\n",
      "clearml.utilities.pigar.utils\n",
      "clearml.utilities.plotly_reporter\n",
      "clearml.utilities.plotlympl\n",
      "clearml.utilities.plotlympl.mplexporter\n",
      "clearml.utilities.plotlympl.mplexporter._py3k_compat\n",
      "clearml.utilities.plotlympl.mplexporter.exporter\n",
      "clearml.utilities.plotlympl.mplexporter.renderers\n",
      "clearml.utilities.plotlympl.mplexporter.renderers.base\n",
      "clearml.utilities.plotlympl.mplexporter.renderers.fake_renderer\n",
      "clearml.utilities.plotlympl.mplexporter.renderers.vega_renderer\n",
      "clearml.utilities.plotlympl.mplexporter.renderers.vincent_renderer\n",
      "clearml.utilities.plotlympl.mplexporter.tools\n",
      "clearml.utilities.plotlympl.mplexporter.utils\n",
      "clearml.utilities.plotlympl.mpltools\n",
      "clearml.utilities.plotlympl.renderer\n",
      "clearml.utilities.process\n",
      "clearml.utilities.process.exit_hooks\n",
      "clearml.utilities.process.mp\n",
      "clearml.utilities.proxy_object\n",
      "clearml.utilities.py3_interop\n",
      "clearml.utilities.pyhocon\n",
      "clearml.utilities.pyhocon.config_parser\n",
      "clearml.utilities.pyhocon.config_tree\n",
      "clearml.utilities.pyhocon.converter\n",
      "clearml.utilities.pyhocon.exceptions\n",
      "clearml.utilities.requests_toolbelt\n",
      "clearml.utilities.requests_toolbelt._compat\n",
      "clearml.utilities.requests_toolbelt.multipart\n",
      "clearml.utilities.requests_toolbelt.multipart.decoder\n",
      "clearml.utilities.requests_toolbelt.multipart.encoder\n",
      "clearml.utilities.resource_monitor\n",
      "clearml.utilities.seed\n",
      "clearml.utilities.version\n",
      "clearml.utilities.wizard\n",
      "clearml.utilities.wizard.user_input\n",
      "clearml.version\n"
     ]
    }
   ],
   "source": [
    "import pkgutil\n",
    "import clearml\n",
    "\n",
    "def list_submodules(package):\n",
    "    return[name for _, name, is_pkg in pkgutil.walk_packages(package.__path__,package.__name__+\".\")]\n",
    "\n",
    "submodules=list_submodules(clearml)\n",
    "for submodule in submodules:\n",
    "    print(submodule)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769b0069-a6b4-41ba-9194-1c463e5e718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes and methods in clearml.task:\n",
      "['Any', 'ArgumentParser', 'Artifact', 'Artifacts', 'BackendModel', 'BackgroundMonitor', 'Callable', 'CollectionsSequence', 'DEBUG_SIMULATE_REMOTE_TASK', 'DEV_DEFAULT_OUTPUT_URI', 'DEV_TASK_NO_REUSE', 'DevWorker', 'Dict', 'ENV_ACCESS_KEY', 'ENV_DEFERRED_TASK_INIT', 'ENV_FILES_HOST', 'ENV_HOST', 'ENV_IGNORE_MISSING_CONFIG', 'ENV_OFFLINE_MODE', 'ENV_SECRET_KEY', 'ENV_WEB_HOST', 'EnvironmentBind', 'ExitHooks', 'Framework', 'FutureTaskCaller', 'InputModel', 'InterfaceBase', 'Iterable', 'List', 'Logger', 'LoggerRoot', 'Mapping', 'Metrics', 'MissingConfigError', 'Model', 'Optional', 'OutputModel', 'PatchAbsl', 'PatchCatBoostModelIO', 'PatchClick', 'PatchFastai', 'PatchFire', 'PatchGradio', 'PatchHydra', 'PatchJsonArgParse', 'PatchLIGHTgbmModelIO', 'PatchMegEngineModelIO', 'PatchOsFork', 'PatchPyTorchModelIO', 'PatchXGBoostModelIO', 'PatchedJoblib', 'PatchedMatplotlib', 'Path', 'ProxyDictPostWrite', 'ProxyDictPreWrite', 'ReadOnlyDict', 'RequirementsDict', 'ResourceMonitor', 'ScriptInfo', 'Sequence', 'Session', 'SessionCache', 'TASK_SET_ITERATION_OFFSET', 'TYPE_CHECKING', 'Task', 'TaskHandler', 'TaskInstance', 'TaskModels', 'TaskParameters', 'TensorflowBinding', 'Tuple', 'TypeVar', 'Union', 'UsageError', 'WeightsFileHandler', 'ZIP_DEFLATED', 'ZipFile', '_Arguments', '_Task', '_TaskStub', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'argparser_parseargs_called', 'argparser_update_currenttask', 'config', 'copy', 'create_torch_distributed_anchor', 'deferred_config', 'events', 'exact_match_regex', 'flatten_dictionary', 'getLogger', 'get_active_config_file', 'get_argparser_last_args', 'get_config_file', 'get_current_thread_id', 'get_is_master_node', 'get_num_enqueued_tasks', 'get_or_create_project', 'get_private_ip', 'get_queue_id', 'get_remote_task_id', 'get_single_result', 'get_torch_distributed_anchor_task_id', 'get_torch_local_rank', 'json', 'leave_process', 'make_deterministic', 'make_message', 'matches_any_wildcard', 'merge_dicts', 'mkdtemp', 'mkstemp', 'mutually_exclusive', 'naive_nested_from_flat_dictionary', 'nested_from_flat_dictionary', 'os', 'projects', 'psutil', 'running_remotely', 'shutil', 'six', 'sys', 'tasks', 'threading', 'time', 'verify_basic_value', 'warnings']\n",
      "\n",
      "Detailed information about clearml.task:\n",
      "Help on module clearml.task in clearml:\n",
      "\n",
      "NAME\n",
      "    clearml.task\n",
      "\n",
      "CLASSES\n",
      "    clearml.backend_interface.task.task.Task(clearml.backend_interface.base.IdObjectBase, clearml.backend_interface.task.access.AccessMixin, clearml.backend_interface.setupuploadmixin.SetupUploadMixin)\n",
      "        Task\n",
      "    \n",
      "    class Task(clearml.backend_interface.task.task.Task)\n",
      "     |  Task(private=None, **kwargs)\n",
      "     |  \n",
      "     |  The ``Task`` class is a code template for a Task object which, together with its connected experiment components,\n",
      "     |  represents the current running experiment. These connected components include hyperparameters, loggers,\n",
      "     |  configuration, label enumeration, models, and other artifacts.\n",
      "     |  \n",
      "     |  The term \"main execution Task\" refers to the Task context for current running experiment. Python experiment scripts\n",
      "     |  can create one, and only one, main execution Task. It is traceable, and after a script runs and ClearML stores\n",
      "     |  the Task in the **ClearML Server** (backend), it is modifiable, reproducible, executable by a worker, and you\n",
      "     |  can duplicate it for further experimentation.\n",
      "     |  \n",
      "     |  The ``Task`` class and its methods allow you to create and manage experiments, as well as perform\n",
      "     |  advanced experimentation functions, such as autoML.\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |      Do not construct Task objects directly. Use one of the methods listed below to create experiments or\n",
      "     |      reference existing experiments.\n",
      "     |      Do not define `CLEARML_TASK_*` and `CLEARML_PROC_*` OS environments, they are used internally\n",
      "     |      for bookkeeping between processes and agents.\n",
      "     |  \n",
      "     |  For detailed information about creating Task objects, see the following methods:\n",
      "     |  \n",
      "     |  - Create a new reproducible Task - :meth:`Task.init`\n",
      "     |  \n",
      "     |  .. important::\n",
      "     |      In some cases, ``Task.init`` may return a Task object which is already stored in **ClearML Server** (already\n",
      "     |      initialized), instead of creating a new Task. For a detailed explanation of those cases, see the ``Task.init``\n",
      "     |      method.\n",
      "     |  \n",
      "     |  - Manually create a new Task (no auto-logging will apply) - :meth:`Task.create`\n",
      "     |  - Get the current running Task - :meth:`Task.current_task`\n",
      "     |  - Get another (different) Task - :meth:`Task.get_task`\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |      The **ClearML** documentation often refers to a Task as, \"Task (experiment)\".\n",
      "     |  \n",
      "     |      \"Task\" refers to the class in the ClearML Python Client Package, the object in your Python experiment script,\n",
      "     |      and the entity with which **ClearML Server** and **ClearML Agent** work.\n",
      "     |  \n",
      "     |      \"Experiment\" refers to your deep learning solution, including its connected components, inputs, and outputs,\n",
      "     |      and is the experiment you can view, analyze, compare, modify, duplicate, and manage using the ClearML\n",
      "     |      **Web-App** (UI).\n",
      "     |  \n",
      "     |      Therefore, a \"Task\" is effectively an \"experiment\", and \"Task (experiment)\" encompasses its usage throughout\n",
      "     |      the ClearML.\n",
      "     |  \n",
      "     |      The exception to this Task behavior is sub-tasks (non-reproducible Tasks), which do not use the main execution\n",
      "     |      Task. Creating a sub-task always creates a new Task with a new  Task ID.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Task\n",
      "     |      clearml.backend_interface.task.task.Task\n",
      "     |      clearml.backend_interface.base.IdObjectBase\n",
      "     |      clearml.backend_interface.base.InterfaceBase\n",
      "     |      clearml.backend_interface.session.SessionInterface\n",
      "     |      clearml.backend_interface.task.access.AccessMixin\n",
      "     |      clearml.backend_interface.setupuploadmixin.SetupUploadMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, private=None, **kwargs)\n",
      "     |      .. warning::\n",
      "     |          **Do not construct Task manually!**\n",
      "     |          Please use :meth:`Task.init` or :meth:`Task.get_task`\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  add_tags(self, tags)\n",
      "     |      Add Tags to this task. Old tags are not deleted. When executing a Task (experiment) remotely,\n",
      "     |      this method has no effect.\n",
      "     |      \n",
      "     |      :param tags: A list of tags which describe the Task to add.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes the current Task and changes its status to \"Completed\".\n",
      "     |      Enables you to manually shut down the task from the process which opened the task.\n",
      "     |      \n",
      "     |      This method does not terminate the (current) Python process, in contrast to :meth:`Task.mark_completed`.\n",
      "     |      \n",
      "     |      After having :meth:`Task.close` -d a task, the respective object cannot be used anymore and\n",
      "     |      methods like :meth:`Task.connect` or :meth:`Task.connect_configuration` will throw a `ValueError`.\n",
      "     |      In order to obtain an object representing the task again, use methods like :meth:`Task.get_task`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |         Only call :meth:`Task.close` if you are certain the Task is not needed.\n",
      "     |  \n",
      "     |  connect(self, mutable, name=None, ignore_remote_overrides=False)\n",
      "     |      Connect an object to a Task object. This connects an experiment component (part of an experiment) to the\n",
      "     |      experiment. For example, an experiment component can be a valid object containing some hyperparameters, or a :class:`Model`.\n",
      "     |      When running remotely, the value of the connected object is overridden by the corresponding value found\n",
      "     |      under the experiment's UI/backend (unless `ignore_remote_overrides` is True).\n",
      "     |      \n",
      "     |      :param object mutable: The experiment component to connect. The object must be one of the following types:\n",
      "     |      \n",
      "     |        - argparse - An argparse object for parameters.\n",
      "     |        - dict - A dictionary for parameters. Note: only keys of type `str` are supported.\n",
      "     |        - TaskParameters - A TaskParameters object.\n",
      "     |        - :class:`Model` - A model object for initial model warmup, or for model update/snapshot uploading. In practice the model should be either :class:`InputModel` or :class:`OutputModel`.\n",
      "     |        - type - A Class type, storing all class properties (excluding '_' prefixed properties).\n",
      "     |        - object - A class instance, storing all instance properties (excluding '_' prefixed properties).\n",
      "     |      \n",
      "     |      :param str name: A section name associated with the connected object, if 'name' is None defaults to 'General'\n",
      "     |          Currently, `name` is only supported for `dict` and `TaskParameter` objects, and should be omitted for the other supported types. (Optional)\n",
      "     |          For example, by setting `name='General'` the connected dictionary will be under the General section in the hyperparameters section.\n",
      "     |          While by setting `name='Train'` the connected dictionary will be under the Train section in the hyperparameters section.\n",
      "     |      \n",
      "     |      :param ignore_remote_overrides: If True, ignore UI/backend overrides when running remotely.\n",
      "     |      Default is False, meaning that any changes made in the UI/backend will be applied in remote execution.\n",
      "     |      \n",
      "     |      :return: It will return the same object that was passed as the `mutable` argument to the method, except if the type of the object is dict.\n",
      "     |               For dicts the :meth:`Task.connect` will return the dict decorated as a `ProxyDictPostWrite`.\n",
      "     |               This is done to allow propagating the updates from the connected object.\n",
      "     |      \n",
      "     |      :raise: Raises an exception if passed an unsupported object.\n",
      "     |  \n",
      "     |  connect_configuration(self, configuration, name=None, description=None, ignore_remote_overrides=False)\n",
      "     |      Connect a configuration dictionary or configuration file (pathlib.Path / str) to a Task object.\n",
      "     |      This method should be called before reading the configuration file.\n",
      "     |      \n",
      "     |      For example, a local file:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |         config_file = task.connect_configuration(config_file)\n",
      "     |         my_params = json.load(open(config_file,'rt'))\n",
      "     |      \n",
      "     |      A parameter dictionary/list:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |         my_params = task.connect_configuration(my_params)\n",
      "     |      \n",
      "     |      When running remotely, the value of the connected configuration is overridden by the corresponding value found\n",
      "     |      under the experiment's UI/backend (unless `ignore_remote_overrides` is True).\n",
      "     |      \n",
      "     |      :param configuration: The configuration. This is usually the configuration used in the model training process.\n",
      "     |          Specify one of the following:\n",
      "     |      \n",
      "     |        - A dictionary/list - A dictionary containing the configuration. ClearML stores the configuration in\n",
      "     |            the **ClearML Server** (backend), in a HOCON format (JSON-like format) which is editable.\n",
      "     |        - A ``pathlib2.Path`` string - A path to the configuration file. ClearML stores the content of the file.\n",
      "     |            A local path must be relative path. When executing a Task remotely in a worker, the contents brought\n",
      "     |            from the **ClearML Server** (backend) overwrites the contents of the file.\n",
      "     |      \n",
      "     |      :param str name: Configuration section name. default: 'General'\n",
      "     |          Allowing users to store multiple configuration dicts/files\n",
      "     |      \n",
      "     |      :param str description: Configuration section description (text). default: None\n",
      "     |      \n",
      "     |      :param bool ignore_remote_overrides: If True, ignore UI/backend overrides when running remotely.\n",
      "     |      Default is False, meaning that any changes made in the UI/backend will be applied in remote execution.\n",
      "     |      \n",
      "     |      :return: If a dictionary is specified, then a dictionary is returned. If pathlib2.Path / string is\n",
      "     |          specified, then a path to a local configuration file is returned. Configuration object.\n",
      "     |  \n",
      "     |  connect_label_enumeration(self, enumeration, ignore_remote_overrides=False)\n",
      "     |      Connect a label enumeration dictionary to a Task (experiment) object.\n",
      "     |      \n",
      "     |      Later, when creating an output model, the model will include the label enumeration dictionary.\n",
      "     |      \n",
      "     |      :param dict enumeration: A label enumeration dictionary of string (label) to integer (value) pairs.\n",
      "     |      \n",
      "     |          For example:\n",
      "     |      \n",
      "     |          .. code-block:: javascript\n",
      "     |      \n",
      "     |             {\n",
      "     |                  \"background\": 0,\n",
      "     |                  \"person\": 1\n",
      "     |             }\n",
      "     |      \n",
      "     |      :param ignore_remote_overrides: If True, ignore UI/backend overrides when running remotely.\n",
      "     |          Default is False, meaning that any changes made in the UI/backend will be applied in remote execution.\n",
      "     |      :return: The label enumeration dictionary (JSON).\n",
      "     |  \n",
      "     |  create_function_task(self, func, func_name=None, task_name=None, **kwargs)\n",
      "     |      Create a new task, and call ``func`` with the specified kwargs.\n",
      "     |      One can think of this call as remote forking, where the newly created instance is the new Task\n",
      "     |      calling the specified func with the appropriate kwargs and leaving once the func terminates.\n",
      "     |      Notice that a remote executed function cannot create another child remote executed function.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          - Must be called from the main Task, i.e. the one created by Task.init(...)\n",
      "     |          - The remote Tasks inherits the environment from the creating Task\n",
      "     |          - In the remote Task, the entrypoint is the same as the creating Task\n",
      "     |          - In the remote Task, the execution is the same until reaching this function call\n",
      "     |      \n",
      "     |      :param func: A function to execute remotely as a single Task.\n",
      "     |          On the remote executed Task the entry-point and the environment are copied from this\n",
      "     |          calling process, only this function call redirect the execution flow to the called func,\n",
      "     |          alongside the passed arguments\n",
      "     |      :param func_name: A unique identifier of the function. Default the function name without the namespace.\n",
      "     |          For example Class.foo() becomes 'foo'\n",
      "     |      :param task_name: The newly created Task name. Default: the calling Task name + function name\n",
      "     |      :param kwargs: name specific arguments for the target function.\n",
      "     |          These arguments will appear under the configuration, \"Function\" section\n",
      "     |      \n",
      "     |      :return Task: Return the newly created Task or None if running remotely and execution is skipped\n",
      "     |  \n",
      "     |  delete(self, delete_artifacts_and_models=True, skip_models_used_by_other_tasks=True, raise_on_error=False, callback=None)\n",
      "     |      Delete the task as well as its output models and artifacts.\n",
      "     |      Models and artifacts are deleted from their storage locations, each using its URI.\n",
      "     |      \n",
      "     |      Note: in order to delete models and artifacts using their URI, make sure the proper storage credentials are\n",
      "     |      configured in your configuration file (e.g. if an artifact is stored in S3, make sure sdk.aws.s3.credentials\n",
      "     |      are properly configured and that you have delete permission in the related buckets).\n",
      "     |      \n",
      "     |      :param delete_artifacts_and_models: If True, artifacts and models would also be deleted (default True).\n",
      "     |                                          If callback is provided, this argument is ignored.\n",
      "     |      :param skip_models_used_by_other_tasks: If True, models used by other tasks would not be deleted (default True)\n",
      "     |      :param raise_on_error: If True, an exception will be raised when encountering an error.\n",
      "     |                             If False an error would be printed and no exception will be raised.\n",
      "     |      :param callback: An optional callback accepting a uri type (string) and a uri (string) that will be called\n",
      "     |                       for each artifact and model. If provided, the delete_artifacts_and_models is ignored.\n",
      "     |                       Return True to indicate the artifact/model should be deleted or False otherwise.\n",
      "     |      :return: True if the task was deleted successfully.\n",
      "     |  \n",
      "     |  delete_user_properties(self, *iterables)\n",
      "     |      Delete hyperparameters for this task.\n",
      "     |      \n",
      "     |      :param iterables: Hyperparameter key iterables. Each an iterable whose possible values each represent\n",
      "     |          a hyperparameter entry to delete, value formats are:\n",
      "     |      \n",
      "     |          * A dictionary containing a 'section' and 'name' fields\n",
      "     |          * An iterable (e.g. tuple, list etc.) whose first two items denote 'section' and 'name'\n",
      "     |  \n",
      "     |  execute_remotely(self, queue_name=None, clone=False, exit_process=True)\n",
      "     |      If task is running locally (i.e., not by ``clearml-agent``), then clone the Task and enqueue it for remote\n",
      "     |      execution; or, stop the execution of the current Task, reset its state, and enqueue it. If ``exit==True``,\n",
      "     |      *exit* this process.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          If the task is running remotely (i.e., ``clearml-agent`` is executing it), this call is a no-op\n",
      "     |          (i.e., does nothing).\n",
      "     |      \n",
      "     |      :param queue_name: The queue name used for enqueueing the task. If ``None``, this call exits the process\n",
      "     |          without enqueuing the task.\n",
      "     |      :param clone: Clone the Task and execute the newly cloned Task\n",
      "     |          The values are:\n",
      "     |      \n",
      "     |        - ``True`` - A cloned copy of the Task will be created, and enqueued, instead of this Task.\n",
      "     |        - ``False`` - The Task will be enqueued.\n",
      "     |      \n",
      "     |      :param exit_process: The function call will leave the calling process at the end.\n",
      "     |      \n",
      "     |        - ``True`` - Exit the process (exit(0)). Note: if ``clone==False``, then ``exit_process`` must be ``True``.\n",
      "     |        - ``False`` - Do not exit the process.\n",
      "     |      \n",
      "     |      :return Task: return the task object of the newly generated remotely executing task\n",
      "     |  \n",
      "     |  export_task(self)\n",
      "     |      Export Task's configuration into a dictionary (for serialization purposes).\n",
      "     |      A Task can be copied/modified by calling Task.import_task()\n",
      "     |      Notice: Export task does not include the tasks outputs, such as results\n",
      "     |      (scalar/plots etc.) or Task artifacts/models\n",
      "     |      \n",
      "     |      :return: dictionary of the Task's configuration.\n",
      "     |  \n",
      "     |  flush(self, wait_for_uploads=False)\n",
      "     |      Flush any outstanding reports or console logs.\n",
      "     |      \n",
      "     |      :param bool wait_for_uploads: Wait for all outstanding uploads to complete\n",
      "     |      \n",
      "     |          - ``True`` - Wait\n",
      "     |          - ``False`` - Do not wait (default)\n",
      "     |  \n",
      "     |  get_debug_samples(self, title, series, n_last_iterations=None)\n",
      "     |      :param str title: Debug sample's title, also called metric in the UI\n",
      "     |      :param str series: Debug sample's series,\n",
      "     |          corresponding to debug sample's file name in the UI, also known as variant\n",
      "     |      :param int n_last_iterations: How many debug sample iterations to fetch in reverse chronological order.\n",
      "     |          Leave empty to get all debug samples.\n",
      "     |      \n",
      "     |      :raise: TypeError if `n_last_iterations` is explicitly set to anything other than a positive integer value\n",
      "     |      \n",
      "     |      :return: A list of `dict`s, each dictionary containing the debug sample's URL and other metadata.\n",
      "     |          The URLs can be passed to StorageManager.get_local_copy to fetch local copies of debug samples.\n",
      "     |  \n",
      "     |  get_initial_iteration(self)\n",
      "     |      Return the initial iteration offset, default is 0\n",
      "     |      Useful when continuing training from previous checkpoints\n",
      "     |      \n",
      "     |      :return: Initial iteration offset.\n",
      "     |  \n",
      "     |  get_last_iteration(self)\n",
      "     |      Get the last reported iteration, which is the last iteration for which the Task reported a metric.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         The maximum reported iteration is not in the local cache. This method\n",
      "     |         sends a request to the **ClearML Server** (backend).\n",
      "     |      \n",
      "     |      :return: The last reported iteration number.\n",
      "     |  \n",
      "     |  get_last_scalar_metrics(self)\n",
      "     |      Get the last scalar metrics which the Task reported. This is a nested dictionary, ordered by title and series.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      .. code-block:: javascript\n",
      "     |      \n",
      "     |         {\n",
      "     |          \"title\": {\n",
      "     |              \"series\": {\n",
      "     |                  \"last\": 0.5,\n",
      "     |                  \"min\": 0.1,\n",
      "     |                  \"max\": 0.9\n",
      "     |                  }\n",
      "     |              }\n",
      "     |          }\n",
      "     |      \n",
      "     |      :return: The last scalar metrics.\n",
      "     |  \n",
      "     |  get_logger(self)\n",
      "     |      Get a Logger object for reporting, for this task context. You can view all Logger report output associated with\n",
      "     |      the Task for which this method is called, including metrics, plots, text, tables, and images, in the\n",
      "     |      **ClearML Web-App (UI)**.\n",
      "     |      \n",
      "     |      :return: The Logger for the Task (experiment).\n",
      "     |  \n",
      "     |  get_model_config_dict(self)\n",
      "     |      .. deprecated:: 0.14.1\n",
      "     |          Use :meth:`Task.connect_configuration` instead.\n",
      "     |  \n",
      "     |  get_model_config_text(self)\n",
      "     |      .. deprecated:: 0.14.1\n",
      "     |          Use :meth:`Task.connect_configuration` instead.\n",
      "     |  \n",
      "     |  get_models(self)\n",
      "     |      Return a dictionary with {'input': [], 'output': []} loaded/stored models of the current Task\n",
      "     |      Input models are files loaded in the task, either manually or automatically logged\n",
      "     |      Output models are files stored in the task, either manually or automatically logged.\n",
      "     |      Automatically logged frameworks are for example: TensorFlow, Keras, PyTorch, ScikitLearn(joblib) etc.\n",
      "     |      \n",
      "     |      :return: A dictionary-like object with \"input\"/\"output\" keys and input/output properties, pointing to a\n",
      "     |          list-like object containing Model objects. Each list-like object also acts as a dictionary, mapping\n",
      "     |          model name to an appropriate model instance.\n",
      "     |      \n",
      "     |          Example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              {'input': [clearml.Model()], 'output': [clearml.Model()]}\n",
      "     |  \n",
      "     |  get_parameters_as_dict(self, cast=False)\n",
      "     |      Get the Task parameters as a raw nested dictionary.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         If `cast` is False (default) The values are not parsed. They are returned as is.\n",
      "     |      \n",
      "     |      :param cast: If True, cast the parameter to the original type. Default False,\n",
      "     |          values are returned in their string representation\n",
      "     |  \n",
      "     |  get_progress(self)\n",
      "     |      Gets Task's progress (0 - 100)\n",
      "     |      \n",
      "     |      :return: Task's progress as an int.\n",
      "     |          In case the progress doesn't exist, None will be returned\n",
      "     |  \n",
      "     |  get_registered_artifacts(self)\n",
      "     |      Get a dictionary containing the Task's registered (dynamically synchronized) artifacts (name, artifact object).\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         After calling ``get_registered_artifacts``, you can still modify the registered artifacts.\n",
      "     |      \n",
      "     |      :return: The registered (dynamically synchronized) artifacts.\n",
      "     |  \n",
      "     |  get_requirements(self)\n",
      "     |      Get the task's requirements\n",
      "     |      \n",
      "     |      :return: A `RequirementsDict` object that holds the `pip`, `conda`, `orig_pip` requirements.\n",
      "     |  \n",
      "     |  get_script(self)\n",
      "     |      Get task's script details.\n",
      "     |      \n",
      "     |      Returns a dictionary containing the script details.\n",
      "     |      \n",
      "     |      :return: Dictionary with script properties e.g.\n",
      "     |      \n",
      "     |      .. code-block:: javascript\n",
      "     |      \n",
      "     |         {\n",
      "     |              'working_dir': 'examples/reporting',\n",
      "     |              'entry_point': 'artifacts.py',\n",
      "     |              'branch': 'master',\n",
      "     |              'repository': 'https://github.com/allegroai/clearml.git'\n",
      "     |         }\n",
      "     |  \n",
      "     |  get_user_properties(self, value_only=False)\n",
      "     |      Get user properties for this task.\n",
      "     |      Returns a dictionary mapping user property name to user property details dict.\n",
      "     |      \n",
      "     |      :param value_only: If True, returned user property details will be a string representing the property value.\n",
      "     |  \n",
      "     |  is_current_task(self)\n",
      "     |      .. deprecated:: 0.13.0\n",
      "     |         This method is deprecated. Use :meth:`Task.is_main_task` instead.\n",
      "     |      \n",
      "     |      Is this Task object the main execution Task (initially returned by :meth:`Task.init`)\n",
      "     |      \n",
      "     |      :return: Is this Task object the main execution Task\n",
      "     |      \n",
      "     |          - ``True`` - Is the main execution Task.\n",
      "     |          - ``False`` - Is not the main execution Task.\n",
      "     |  \n",
      "     |  is_main_task(self)\n",
      "     |      Is this Task object the main execution Task (initially returned by :meth:`Task.init`)\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         If :meth:`Task.init` was never called, this method will *not* create\n",
      "     |         it, making this test more efficient than:\n",
      "     |      \n",
      "     |         .. code-block:: py\n",
      "     |      \n",
      "     |            Task.init() == task\n",
      "     |      \n",
      "     |      :return: Is this Task object the main execution Task\n",
      "     |      \n",
      "     |          - ``True`` - Is the main execution Task.\n",
      "     |          - ``False`` - Is not the main execution Task.\n",
      "     |  \n",
      "     |  launch_multi_node(self, total_num_nodes, port=29500, queue=None, wait=False, addr=None)\n",
      "     |      Enqueue multiple clones of the current task to a queue, allowing the task\n",
      "     |      to be ran by multiple workers in parallel. Each task running this way is called a node.\n",
      "     |      Each node has a rank The node that initialized the execution of the other nodes\n",
      "     |      is called the `master node` and it has a rank equal to 0.\n",
      "     |      \n",
      "     |      A dictionary named `multi_node_instance` will be connected to the tasks.\n",
      "     |      One can use this dictionary to modify the behaviour of this function when running remotely.\n",
      "     |      The contents of this dictionary correspond to the parameters of this function, and they are:\n",
      "     |      - `total_num_nodes` - the total number of nodes, including the master node\n",
      "     |      - `queue` - the queue to enqueue the nodes to\n",
      "     |      \n",
      "     |      The following environment variables, will be set:\n",
      "     |      - `MASTER_ADDR` - the address of the machine that the master node is running on\n",
      "     |      - `MASTER_PORT` - the open port of the machine that the master node is running on\n",
      "     |      - `WORLD_SIZE` - the total number of nodes, including the master\n",
      "     |      - `RANK` - the rank of the current node (master has rank 0)\n",
      "     |      \n",
      "     |      One may use this function in conjuction with PyTorch's distributed communication package.\n",
      "     |      Note that `Task.launch_multi_node` should be called before `torch.distributed.init_process_group`.\n",
      "     |      For example:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          from clearml import Task\n",
      "     |          import torch\n",
      "     |          import torch.distributed as dist\n",
      "     |      \n",
      "     |          def run(rank, size):\n",
      "     |              print('World size is ', size)\n",
      "     |              tensor = torch.zeros(1)\n",
      "     |              if rank == 0:\n",
      "     |                  for i in range(1, size):\n",
      "     |                      tensor += 1\n",
      "     |                      dist.send(tensor=tensor, dst=i)\n",
      "     |                      print('Sending from rank ', rank, ' to rank ', i, ' data: ', tensor[0])\n",
      "     |              else:\n",
      "     |                  dist.recv(tensor=tensor, src=0)\n",
      "     |                  print('Rank ', rank, ' received data: ', tensor[0])\n",
      "     |      \n",
      "     |          if __name__ == '__main__':\n",
      "     |              task = Task.init('some_name', 'some_name')\n",
      "     |              task.execute_remotely(queue_name='queue')\n",
      "     |              config = task.launch_multi_node(4)\n",
      "     |              dist.init_process_group('gloo')\n",
      "     |              run(config.get('node_rank'), config.get('total_num_nodes'))\n",
      "     |      \n",
      "     |      When using the ClearML cloud autoscaler apps, one needs to make sure the nodes can reach eachother.\n",
      "     |      The machines need to be in the same security group, the `MASTER_PORT` needs to be exposed and the\n",
      "     |      `MASTER_ADDR` needs to be the right private ip of the instance the master is running on.\n",
      "     |      For example, to achieve this, one can set the following Docker arguments in the `Additional ClearML Configuration` section:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          agent.extra_docker_arguments=[\"--ipc=host\", \"--network=host\", \"-p\", \"29500:29500\", \"--env\", \"CLEARML_MULTI_NODE_MASTER_DEF_ADDR=`hostname -I | awk '{print $1}'`\"]`\n",
      "     |      \n",
      "     |      :param total_num_nodes: The total number of nodes to be enqueued, including the master node,\n",
      "     |          which should already be enqueued when running remotely\n",
      "     |      :param port: Port opened by the master node. If the environment variable ``CLEARML_MULTI_NODE_MASTER_DEF_PORT``\n",
      "     |          is set, the value of this parameter will be set to the one defined in ``CLEARML_MULTI_NODE_MASTER_DEF_PORT``.\n",
      "     |          If ``CLEARML_MULTI_NODE_MASTER_DEF_PORT`` doesn't exist, but ``MASTER_PORT`` does, then the value of this\n",
      "     |          parameter will be set to the one defined in ``MASTER_PORT``. If neither environment variables exist,\n",
      "     |          the value passed to the parameter will be used\n",
      "     |      :param queue: The queue to enqueue the nodes to. Can be different from the queue the master\n",
      "     |          node is enqueued to. If None, the nodes will be enqueued to the same queue as the master node\n",
      "     |      :param wait: If True, the master node will wait for the other nodes to start\n",
      "     |      :param addr: The address of the master node's worker. If the environment variable\n",
      "     |          ``CLEARML_MULTI_NODE_MASTER_DEF_ADDR`` is set, the value of this parameter will be set to\n",
      "     |          the one defined in ``CLEARML_MULTI_NODE_MASTER_DEF_ADDR``.\n",
      "     |          If ``CLEARML_MULTI_NODE_MASTER_DEF_ADDR`` doesn't exist, but ``MASTER_ADDR`` does, then the value of this\n",
      "     |          parameter will be set to the one defined in ``MASTER_ADDR``. If neither environment variables exist,\n",
      "     |          the value passed to the parameter will be used. If this value is None (default), the private IP of\n",
      "     |          the machine the master node is running on will be used.\n",
      "     |      \n",
      "     |      :return: A dictionary containing relevant information regarding the multi node run. This dictionary has the following entries:\n",
      "     |      \n",
      "     |        - `master_addr` - the address of the machine that the master node is running on\n",
      "     |        - `master_port` - the open port of the machine that the master node is running on\n",
      "     |        - `total_num_nodes` - the total number of nodes, including the master\n",
      "     |        - `queue` - the queue the nodes are enqueued to, excluding the master\n",
      "     |        - `node_rank` - the rank of the current node (master has rank 0)\n",
      "     |        - `wait` - if True, the master node will wait for the other nodes to start\n",
      "     |  \n",
      "     |  mark_started(self, force=False)\n",
      "     |      Manually mark a Task as started (happens automatically)\n",
      "     |      \n",
      "     |      :param bool force: If True, the task status will be changed to `started` regardless of the current Task state.\n",
      "     |  \n",
      "     |  mark_stopped(self, force=False, status_message=None)\n",
      "     |      Manually mark a Task as stopped (also used in :meth:`_at_exit`)\n",
      "     |      \n",
      "     |      :param bool force: If True, the task status will be changed to `stopped` regardless of the current Task state.\n",
      "     |      :param str status_message: Optional, add status change message to the stop request.\n",
      "     |          This message will be stored as status_message on the Task's info panel\n",
      "     |  \n",
      "     |  move_to_project(self, new_project_id=None, new_project_name=None, system_tags=None)\n",
      "     |      Move this task to another project\n",
      "     |      \n",
      "     |      :param new_project_id: The ID of the project the task should be moved to.\n",
      "     |          Not required if `new_project_name` is passed.\n",
      "     |      :param new_project_name: Name of the new project the task should be moved to.\n",
      "     |          Not required if `new_project_id` is passed.\n",
      "     |      :param system_tags: System tags for the project the task should be moved to.\n",
      "     |      \n",
      "     |      :return: True if the move was successful and False otherwise\n",
      "     |  \n",
      "     |  register_abort_callback(self, callback_function, callback_execution_timeout=30.0)\n",
      "     |      Register a Task abort callback (single callback function support only).\n",
      "     |      Pass a function to be called from a background thread when the Task is **externally** being aborted.\n",
      "     |      Users must specify a timeout for the callback function execution (default 30 seconds)\n",
      "     |      if the callback execution function exceeds the timeout, the Task's process will be terminated\n",
      "     |      \n",
      "     |      Call this register function from the main process only.\n",
      "     |      \n",
      "     |      Note: Ctrl-C is Not considered external, only backend induced abort is covered here\n",
      "     |      \n",
      "     |      :param callback_function: Callback function to be called via external thread (from the main process).\n",
      "     |          pass None to remove existing callback\n",
      "     |      :param callback_execution_timeout: Maximum callback execution time in seconds, after which the process\n",
      "     |          will be terminated even if the callback did not return\n",
      "     |  \n",
      "     |  register_artifact(self, name, artifact, metadata=None, uniqueness_columns=True)\n",
      "     |      Register (add) an artifact for the current Task. Registered artifacts are dynamically synchronized with the\n",
      "     |      **ClearML Server** (backend). If a registered artifact is updated, the update is stored in the\n",
      "     |      **ClearML Server** (backend). Registered artifacts are primarily used for Data Auditing.\n",
      "     |      \n",
      "     |      The currently supported registered artifact object type is a pandas.DataFrame.\n",
      "     |      \n",
      "     |      See also :meth:`Task.unregister_artifact` and :meth:`Task.get_registered_artifacts`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         ClearML also supports uploaded artifacts which are one-time uploads of static artifacts that are not\n",
      "     |         dynamically synchronized with the **ClearML Server** (backend). These static artifacts include\n",
      "     |         additional object types. For more information, see :meth:`Task.upload_artifact`.\n",
      "     |      \n",
      "     |      :param str name: The name of the artifact.\n",
      "     |      \n",
      "     |       .. warning::\n",
      "     |          If an artifact with the same name was previously registered, it is overwritten.\n",
      "     |      :param object artifact: The artifact object.\n",
      "     |      :param dict metadata: A dictionary of key-value pairs for any metadata. This dictionary appears with the\n",
      "     |          experiment in the **ClearML Web-App (UI)**, **ARTIFACTS** tab.\n",
      "     |      :param uniqueness_columns: A Sequence of columns for artifact uniqueness comparison criteria, or the default\n",
      "     |          value of ``True``. If ``True``, the artifact uniqueness comparison criteria is all the columns,\n",
      "     |          which is the same as ``artifact.columns``.\n",
      "     |  \n",
      "     |  rename(self, new_name)\n",
      "     |      Rename this task\n",
      "     |      \n",
      "     |      :param new_name: The new name of this task\n",
      "     |      \n",
      "     |      :return: True if the rename was successful and False otherwise\n",
      "     |  \n",
      "     |  reset(self, set_started_on_success=False, force=False)\n",
      "     |      Reset a Task. ClearML reloads a Task after a successful reset.\n",
      "     |      When a worker executes a Task remotely, the Task does not reset unless\n",
      "     |      the ``force`` parameter is set to ``True`` (this avoids accidentally clearing logs and metrics).\n",
      "     |      \n",
      "     |      :param bool set_started_on_success: If successful, automatically set the Task to `started`\n",
      "     |      \n",
      "     |          - ``True`` - If successful, set to started.\n",
      "     |          - ``False`` - If successful, do not set to started. (default)\n",
      "     |      \n",
      "     |      :param bool force: Force a Task reset, even when executing the Task (experiment) remotely in a worker\n",
      "     |      \n",
      "     |          - ``True`` - Force\n",
      "     |          - ``False`` - Do not force (default)\n",
      "     |  \n",
      "     |  set_base_docker(self, docker_cmd=None, docker_image=None, docker_arguments=None, docker_setup_bash_script=None)\n",
      "     |      Set the base docker image for this experiment\n",
      "     |      If provided, this value will be used by clearml-agent to execute this experiment\n",
      "     |      inside the provided docker image.\n",
      "     |      When running remotely the call is ignored\n",
      "     |      \n",
      "     |      :param docker_cmd: Deprecated! compound docker container image + arguments\n",
      "     |          (example: 'nvidia/cuda:11.1 -e test=1') Deprecated, use specific arguments.\n",
      "     |      :param docker_image: docker container image (example: 'nvidia/cuda:11.1')\n",
      "     |      :param docker_arguments: docker execution parameters (example: '-e ENV=1')\n",
      "     |      :param docker_setup_bash_script: bash script to run at the\n",
      "     |          beginning of the docker before launching the Task itself. example: ['apt update', 'apt-get install -y gcc']\n",
      "     |  \n",
      "     |  set_initial_iteration(self, offset=0)\n",
      "     |      Set initial iteration, instead of zero. Useful when continuing training from previous checkpoints\n",
      "     |      \n",
      "     |      :param int offset: Initial iteration (at starting point)\n",
      "     |      :return: Newly set initial offset.\n",
      "     |  \n",
      "     |  set_model_config(self, config_text=None, config_dict=None)\n",
      "     |      .. deprecated:: 0.14.1\n",
      "     |          Use :meth:`Task.connect_configuration` instead.\n",
      "     |  \n",
      "     |  set_model_label_enumeration(self, enumeration=None)\n",
      "     |      Set the label enumeration for the Task object before creating an output model.\n",
      "     |      Later, when creating an output model, the model will inherit these properties.\n",
      "     |      \n",
      "     |      :param dict enumeration: A label enumeration dictionary of string (label) to integer (value) pairs.\n",
      "     |      \n",
      "     |          For example:\n",
      "     |      \n",
      "     |          .. code-block:: javascript\n",
      "     |      \n",
      "     |             {\n",
      "     |                  \"background\": 0,\n",
      "     |                  \"person\": 1\n",
      "     |             }\n",
      "     |  \n",
      "     |  set_packages(self, packages)\n",
      "     |      Manually specify a list of required packages or a local requirements.txt file. Note that this will\n",
      "     |      overwrite all existing packages.\n",
      "     |      \n",
      "     |      When running remotely this call is ignored\n",
      "     |      \n",
      "     |      :param packages: The list of packages or the path to the requirements.txt file.\n",
      "     |      \n",
      "     |          Example: [\"tqdm>=2.1\", \"scikit-learn\"] or \"./requirements.txt\" or \"\"\n",
      "     |          Use an empty string (packages=\"\") to clear the requirements section (remote execution will use\n",
      "     |              requirements.txt from the git repository if the file exists)\n",
      "     |  \n",
      "     |  set_parameters_as_dict(self, dictionary)\n",
      "     |      Set the parameters for the Task object from a dictionary. The dictionary can be nested.\n",
      "     |      This does not link the dictionary to the Task object. It does a one-time update. This\n",
      "     |      is the same behavior as the :meth:`Task.connect` method.\n",
      "     |  \n",
      "     |  set_progress(self, progress)\n",
      "     |      Sets Task's progress (0 - 100)\n",
      "     |      Progress is a field computed and reported by the user.\n",
      "     |      \n",
      "     |      :param progress: numeric value (0 - 100)\n",
      "     |  \n",
      "     |  set_repo(self, repo=None, branch=None, commit=None)\n",
      "     |      Specify a repository to attach to the function.\n",
      "     |      Allow users to execute the task inside the specified repository, enabling them to load modules/script\n",
      "     |      from the repository. Notice the execution work directory will be the repository root folder.\n",
      "     |      Supports both git repo url link, and local repository path (automatically converted into the remote\n",
      "     |      git/commit as is currently checkout).\n",
      "     |      Example remote url: \"https://github.com/user/repo.git\".\n",
      "     |      Example local repo copy: \"./repo\" -> will automatically store the remote\n",
      "     |      repo url and commit ID based on the locally cloned copy.\n",
      "     |      When executing remotely, this call will not override the repository data (it is ignored)\n",
      "     |      \n",
      "     |      :param repo: Optional, remote URL for the repository to use, OR path to local copy of the git repository.\n",
      "     |          Use an empty string to clear the repo.\n",
      "     |          Example: \"https://github.com/allegroai/clearml.git\" or \"~/project/repo\" or \"\"\n",
      "     |      :param branch: Optional, specify the remote repository branch (Ignored, if local repo path is used).\n",
      "     |          Use an empty string to clear the branch.\n",
      "     |      :param commit: Optional, specify the repository commit ID (Ignored, if local repo path is used).\n",
      "     |          Use an empty string to clear the commit.\n",
      "     |  \n",
      "     |  set_resource_monitor_iteration_timeout(self, seconds_from_start=1800)\n",
      "     |      Set the ResourceMonitor maximum duration (in seconds) to wait until first scalar/plot is reported.\n",
      "     |      If timeout is reached without any reporting, the ResourceMonitor will start reporting machine statistics based\n",
      "     |      on seconds from Task start time (instead of based on iteration)\n",
      "     |      \n",
      "     |      :param seconds_from_start: Maximum number of seconds to wait for scalar/plot reporting before defaulting\n",
      "     |          to machine statistics reporting based on seconds from experiment start time\n",
      "     |      :return: True if success\n",
      "     |  \n",
      "     |  set_script(self, repository=None, branch=None, commit=None, diff=None, working_dir=None, entry_point=None)\n",
      "     |      Set task's script.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          task.set_script(\n",
      "     |              repository='https://github.com/allegroai/clearml.git,\n",
      "     |              branch='main',\n",
      "     |              working_dir='examples/reporting',\n",
      "     |              entry_point='artifacts.py'\n",
      "     |          )\n",
      "     |      \n",
      "     |      :param repository: Optional, URL of remote repository. use empty string (\"\") to clear repository entry.\n",
      "     |      :param branch: Optional, Select specific repository branch / tag. use empty string (\"\") to clear branch entry.\n",
      "     |      :param commit: Optional, set specific git commit id. use empty string (\"\") to clear commit ID entry.\n",
      "     |      :param diff: Optional, set \"git diff\" section. use empty string (\"\") to clear git-diff entry.\n",
      "     |      :param working_dir: Optional, Working directory to launch the script from.\n",
      "     |      :param entry_point: Optional, Path to execute within the repository.\n",
      "     |  \n",
      "     |  set_user_properties(self, *iterables, **properties)\n",
      "     |      Set user properties for this task.\n",
      "     |      A user property can contain the following fields (all of type string):\n",
      "     |      name / value / description / type\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          task.set_user_properties(backbone='great', stable=True)\n",
      "     |          task.set_user_properties(backbone={\"type\": int, \"description\": \"network type\", \"value\": \"great\"}, )\n",
      "     |          task.set_user_properties(\n",
      "     |              {\"name\": \"backbone\", \"description\": \"network type\", \"value\": \"great\"},\n",
      "     |              {\"name\": \"stable\", \"description\": \"is stable\", \"value\": True},\n",
      "     |          )\n",
      "     |      \n",
      "     |      :param iterables: Properties iterables, each can be:\n",
      "     |      \n",
      "     |          * A dictionary of string key (name) to either a string value (value) a dict (property details). If the value\n",
      "     |              is a dict, it must contain a \"value\" field. For example:\n",
      "     |      \n",
      "     |              .. code-block:: javascript\n",
      "     |      \n",
      "     |                  {\n",
      "     |                      \"property_name\": {\"description\": \"This is a user property\", \"value\": \"property value\"},\n",
      "     |                      \"another_property_name\": {\"description\": \"This is user property\", \"value\": \"another value\"},\n",
      "     |                      \"yet_another_property_name\": \"some value\"\n",
      "     |                  }\n",
      "     |      \n",
      "     |      \n",
      "     |          * An iterable of dicts (each representing property details). Each dict must contain a \"name\" field and a\n",
      "     |              \"value\" field. For example:\n",
      "     |      \n",
      "     |              .. code-block:: javascript\n",
      "     |      \n",
      "     |                  [\n",
      "     |                      {\n",
      "     |                          \"name\": \"property_name\",\n",
      "     |                          \"description\": \"This is a user property\",\n",
      "     |                          \"value\": \"property value\"\n",
      "     |                      },\n",
      "     |                      {\n",
      "     |                          \"name\": \"another_property_name\",\n",
      "     |                          \"description\": \"This is another user property\",\n",
      "     |                          \"value\": \"another value\"\n",
      "     |                      }\n",
      "     |                  ]\n",
      "     |      \n",
      "     |      :param properties: Additional properties keyword arguments. Key is the property name, and value can be\n",
      "     |          a string (property value) or a dict (property details). If the value is a dict, it must contain a \"value\"\n",
      "     |          field. For example:\n",
      "     |      \n",
      "     |          .. code-block:: javascript\n",
      "     |      \n",
      "     |              {\n",
      "     |                  \"property_name\": \"string as property value\",\n",
      "     |                  \"another_property_name\": {\n",
      "     |                      \"type\": \"string\",\n",
      "     |                      \"description\": \"This is user property\",\n",
      "     |                      \"value\": \"another value\"\n",
      "     |                  }\n",
      "     |              }\n",
      "     |  \n",
      "     |  unregister_artifact(self, name)\n",
      "     |      Unregister (remove) a registered artifact. This removes the artifact from the watch list that ClearML uses\n",
      "     |      to synchronize artifacts with the **ClearML Server** (backend).\n",
      "     |      \n",
      "     |      .. important::\n",
      "     |         - Calling this method does not remove the artifact from a Task. It only stops ClearML from\n",
      "     |           monitoring the artifact.\n",
      "     |         - When this method is called, ClearML immediately takes the last snapshot of the artifact.\n",
      "     |  \n",
      "     |  update_task(self, task_data)\n",
      "     |      Update current task with configuration found on the task_data dictionary.\n",
      "     |      See also export_task() for retrieving Task configuration.\n",
      "     |      \n",
      "     |      :param task_data: dictionary with full Task configuration\n",
      "     |      :return: return True if Task update was successful\n",
      "     |  \n",
      "     |  upload_artifact(self, name, artifact_object, metadata=None, delete_after_upload=False, auto_pickle=True, preview=None, wait_on_upload=False, extension_name=None, serialization_function=None, retries=0)\n",
      "     |      Upload (add) a static artifact to a Task object. The artifact is uploaded in the background.\n",
      "     |      \n",
      "     |      The currently supported upload (static) artifact types include:\n",
      "     |      \n",
      "     |      - string / pathlib2.Path - A path to artifact file. If a wildcard or a folder is specified, then ClearML\n",
      "     |        creates and uploads a ZIP file.\n",
      "     |      - dict - ClearML stores a dictionary as ``.json`` (or see ``extension_name``) file and uploads it.\n",
      "     |      - pandas.DataFrame - ClearML stores a pandas.DataFrame as ``.csv.gz`` (compressed CSV)\n",
      "     |        (or see ``extension_name``) file and uploads it.\n",
      "     |      - numpy.ndarray - ClearML stores a numpy.ndarray as ``.npz`` (or see ``extension_name``) file and uploads it.\n",
      "     |      - PIL.Image - ClearML stores a PIL.Image as ``.png`` (or see ``extension_name``) file and uploads it.\n",
      "     |      - Any - If called with auto_pickle=True, the object will be pickled and uploaded.\n",
      "     |      \n",
      "     |      :param str name: The artifact name.\n",
      "     |      \n",
      "     |          .. warning::\n",
      "     |             If an artifact with the same name was previously uploaded, then it is overwritten.\n",
      "     |      \n",
      "     |      :param object artifact_object:  The artifact object.\n",
      "     |      :param dict metadata: A dictionary of key-value pairs for any metadata. This dictionary appears with the\n",
      "     |          experiment in the **ClearML Web-App (UI)**, **ARTIFACTS** tab.\n",
      "     |      :param bool delete_after_upload: After the upload, delete the local copy of the artifact\n",
      "     |      \n",
      "     |          - ``True`` - Delete the local copy of the artifact.\n",
      "     |          - ``False`` - Do not delete. (default)\n",
      "     |      \n",
      "     |      :param bool auto_pickle: If True (default) and the artifact_object is not one of the following types:\n",
      "     |          pathlib2.Path, dict, pandas.DataFrame, numpy.ndarray, PIL.Image, url (string), local_file (string),\n",
      "     |          the artifact_object will be pickled and uploaded as pickle file artifact (with file extension .pkl)\n",
      "     |      \n",
      "     |      :param Any preview: The artifact preview\n",
      "     |      \n",
      "     |      :param bool wait_on_upload: Whether the upload should be synchronous, forcing the upload to complete\n",
      "     |          before continuing.\n",
      "     |      \n",
      "     |      :param str extension_name: File extension which indicates the format the artifact should be stored as.\n",
      "     |          The following are supported, depending on the artifact type (default value applies when extension_name is None):\n",
      "     |      \n",
      "     |        - Any - ``.pkl`` if passed supersedes any other serialization type, and always pickles the object\n",
      "     |        - dict - ``.json``, ``.yaml`` (default ``.json``)\n",
      "     |        - pandas.DataFrame - ``.csv.gz``, ``.parquet``, ``.feather``, ``.pickle`` (default ``.csv.gz``)\n",
      "     |        - numpy.ndarray - ``.npz``, ``.csv.gz`` (default ``.npz``)\n",
      "     |        - PIL.Image - whatever extensions PIL supports (default ``.png``)\n",
      "     |        - In case the ``serialization_function`` argument is set - any extension is supported\n",
      "     |      \n",
      "     |      :param Callable[Any, Union[bytes, bytearray]] serialization_function: A serialization function that takes one\n",
      "     |          parameter of any type which is the object to be serialized. The function should return\n",
      "     |          a `bytes` or `bytearray` object, which represents the serialized object. Note that the object will be\n",
      "     |          immediately serialized using this function, thus other serialization methods will not be used\n",
      "     |          (e.g. `pandas.DataFrame.to_csv`), even if possible. To deserialize this artifact when getting\n",
      "     |          it using the `Artifact.get` method, use its `deserialization_function` argument.\n",
      "     |      \n",
      "     |      :param int retries: Number of retries before failing to upload artifact. If 0, the upload is not retried\n",
      "     |      \n",
      "     |      :return: The status of the upload.\n",
      "     |      \n",
      "     |          - ``True`` - Upload succeeded.\n",
      "     |          - ``False`` - Upload failed.\n",
      "     |      \n",
      "     |      :raise: If the artifact object type is not supported, raise a ``ValueError``.\n",
      "     |  \n",
      "     |  wait_for_status(self, status=(<TaskStatusEnum.completed: 'completed'>, <TaskStatusEnum.stopped: 'stopped'>, <TaskStatusEnum.closed: 'closed'>), raise_on_status=(<TaskStatusEnum.failed: 'failed'>,), check_interval_sec=60.0)\n",
      "     |      Wait for a task to reach a defined status.\n",
      "     |      \n",
      "     |      :param status: Status to wait for. Defaults to ('completed', 'stopped', 'closed', )\n",
      "     |      :param raise_on_status: Raise RuntimeError if the status of the tasks matches one of these values.\n",
      "     |          Defaults to ('failed').\n",
      "     |      :param check_interval_sec: Interval in seconds between two checks. Defaults to 60 seconds.\n",
      "     |      \n",
      "     |      :raise: RuntimeError if the status is one of {raise_on_status}.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  clone(source_task=None, name=None, comment=None, parent=None, project=None) from abc.ABCMeta\n",
      "     |      Create a duplicate (a clone) of a Task (experiment). The status of the cloned Task is ``Draft``\n",
      "     |      and modifiable.\n",
      "     |      \n",
      "     |      Use this method to manage experiments and for autoML.\n",
      "     |      \n",
      "     |      :param str source_task: The Task to clone. Specify a Task object or a  Task ID. (Optional)\n",
      "     |      :param str name: The name of the new cloned Task. (Optional)\n",
      "     |      :param str comment: A comment / description for the new cloned Task. (Optional)\n",
      "     |      :param str parent: The ID of the parent Task of the new Task.\n",
      "     |      \n",
      "     |        - If ``parent`` is not specified, then ``parent`` is set to ``source_task.parent``.\n",
      "     |        - If ``parent`` is not specified and ``source_task.parent`` is not available, then ``parent`` set to ``source_task``.\n",
      "     |      \n",
      "     |      :param str project: The ID of the project in which to create the new Task.\n",
      "     |          If ``None``, the new task inherits the original Task's project. (Optional)\n",
      "     |      \n",
      "     |      :return: The new cloned Task (experiment).\n",
      "     |      :rtype: Task\n",
      "     |  \n",
      "     |  create(project_name=None, task_name=None, task_type=None, repo=None, branch=None, commit=None, script=None, working_directory=None, packages=None, requirements_file=None, docker=None, docker_args=None, docker_bash_setup_script=None, argparse_args=None, base_task_id=None, add_task_init_call=True, force_single_script_file=False) from abc.ABCMeta\n",
      "     |      Manually create and populate a new Task (experiment) in the system.\n",
      "     |      If the code does not already contain a call to ``Task.init``, pass add_task_init_call=True,\n",
      "     |      and the code will be patched in remote execution (i.e. when executed by `clearml-agent`)\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         This method **always** creates a new Task.\n",
      "     |         Use :meth:`Task.init` method to automatically create and populate task for the running process.\n",
      "     |         To reference an existing Task, call the  :meth:`Task.get_task` method .\n",
      "     |      \n",
      "     |      :param project_name: Set the project name for the task. Required if base_task_id is None.\n",
      "     |      :param task_name: Set the name of the remote task. Required if base_task_id is None.\n",
      "     |      :param task_type: Optional, The task type to be created. Supported values: 'training', 'testing', 'inference',\n",
      "     |          'data_processing', 'application', 'monitor', 'controller', 'optimizer', 'service', 'qc', 'custom'\n",
      "     |      :param repo: Remote URL for the repository to use, or path to local copy of the git repository\n",
      "     |          Example: 'https://github.com/allegroai/clearml.git' or '~/project/repo'\n",
      "     |      :param branch: Select specific repository branch/tag (implies the latest commit from the branch)\n",
      "     |      :param commit: Select specific commit ID to use (default: latest commit,\n",
      "     |          or when used with local repository matching the local commit id)\n",
      "     |      :param script: Specify the entry point script for the remote execution. When used in tandem with\n",
      "     |          remote git repository the script should be a relative path inside the repository,\n",
      "     |          for example: './source/train.py' . When used with local repository path it supports a\n",
      "     |          direct path to a file inside the local repository itself, for example: '~/project/source/train.py'\n",
      "     |      :param working_directory: Working directory to launch the script from. Default: repository root folder.\n",
      "     |          Relative to repo root or local folder.\n",
      "     |      :param packages: Manually specify a list of required packages. Example: [\"tqdm>=2.1\", \"scikit-learn\"]\n",
      "     |          or `True` to automatically create requirements\n",
      "     |          based on locally installed packages (repository must be local).\n",
      "     |      :param requirements_file: Specify requirements.txt file to install when setting the session.\n",
      "     |          If not provided, the requirements.txt from the repository will be used.\n",
      "     |      :param docker: Select the docker image to be executed in by the remote session\n",
      "     |      :param docker_args: Add docker arguments, pass a single string\n",
      "     |      :param docker_bash_setup_script: Add bash script to be executed\n",
      "     |          inside the docker before setting up the Task's environment\n",
      "     |      :param argparse_args: Arguments to pass to the remote execution, list of string pairs (argument, value)\n",
      "     |          Notice, only supported if the codebase itself uses argparse.ArgumentParser\n",
      "     |      :param base_task_id: Use a pre-existing task in the system, instead of a local repo/script.\n",
      "     |          Essentially clones an existing task and overrides arguments/requirements.\n",
      "     |      :param add_task_init_call: If True, a 'Task.init()' call is added to the script entry point in remote execution.\n",
      "     |      :param force_single_script_file: If True, do not auto-detect local repository\n",
      "     |      \n",
      "     |      :return: The newly created Task (experiment)\n",
      "     |      :rtype: Task\n",
      "     |  \n",
      "     |  current_task() from abc.ABCMeta\n",
      "     |      Get the current running Task (experiment). This is the main execution Task (task context) returned as a Task\n",
      "     |      object.\n",
      "     |      \n",
      "     |      :return: The current running Task (experiment).\n",
      "     |      :rtype: Task\n",
      "     |  \n",
      "     |  debug_simulate_remote_task(task_id, reset_task=False) from abc.ABCMeta\n",
      "     |      Simulate remote execution of a specified Task.\n",
      "     |      This call will simulate the behaviour of your Task as if executed by the ClearML-Agent\n",
      "     |      This means configurations will be coming from the backend server into the code\n",
      "     |      (the opposite from manual execution, where the backend logs the code arguments)\n",
      "     |      Use with care.\n",
      "     |      \n",
      "     |      :param task_id: Task ID to simulate, notice that all configuration will be taken from the specified\n",
      "     |          Task, regardless of the code initial values, just like it as if executed by ClearML agent\n",
      "     |      :param reset_task: If True, target Task, is automatically cleared / reset.\n",
      "     |  \n",
      "     |  dequeue(task) from abc.ABCMeta\n",
      "     |      Dequeue (remove) a Task from an execution queue.\n",
      "     |      \n",
      "     |      :param Task/str task: The Task to dequeue. Specify a Task object or  Task ID.\n",
      "     |      \n",
      "     |      :return: A dequeue JSON response.\n",
      "     |      \n",
      "     |      .. code-block:: javascript\n",
      "     |      \n",
      "     |         {\n",
      "     |              \"dequeued\": 1,\n",
      "     |              \"updated\": 1,\n",
      "     |              \"fields\": {\n",
      "     |                  \"status\": \"created\",\n",
      "     |                  \"status_reason\": \"\",\n",
      "     |                  \"status_message\": \"\",\n",
      "     |                  \"status_changed\": \"2020-02-24T16:43:43.057320+00:00\",\n",
      "     |                  \"last_update\": \"2020-02-24T16:43:43.057320+00:00\",\n",
      "     |                  \"execution.queue\": null\n",
      "     |                  }\n",
      "     |          }\n",
      "     |      \n",
      "     |      - ``dequeued``  - The number of Tasks enqueued (an integer or ``null``).\n",
      "     |      - ``fields``\n",
      "     |      \n",
      "     |        - ``status`` - The status of the experiment.\n",
      "     |        - ``status_reason`` - The reason for the last status change.\n",
      "     |        - ``status_message`` - Information about the status.\n",
      "     |        - ``status_changed`` - The last status change date and time in ISO 8601 format.\n",
      "     |        - ``last_update`` - The last time the Task was created, updated,\n",
      "     |              changed, or events for this task were reported.\n",
      "     |        - ``execution.queue`` - The ID of the queue where the Task is enqueued. ``null`` indicates not enqueued.\n",
      "     |      \n",
      "     |      - ``updated`` - The number of Tasks updated (an integer or ``null``).\n",
      "     |  \n",
      "     |  enqueue(task, queue_name=None, queue_id=None, force=False) from abc.ABCMeta\n",
      "     |      Enqueue a Task for execution, by adding it to an execution queue.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         A worker daemon must be listening at the queue for the worker to fetch the Task and execute it,\n",
      "     |         see `ClearML Agent <../clearml_agent>`_ in the ClearML Documentation.\n",
      "     |      \n",
      "     |      :param Task/str task: The Task to enqueue. Specify a Task object or  Task ID.\n",
      "     |      :param str queue_name: The name of the queue. If not specified, then ``queue_id`` must be specified.\n",
      "     |      :param str queue_id: The ID of the queue. If not specified, then ``queue_name`` must be specified.\n",
      "     |      :param bool force: If True, reset the Task if necessary before enqueuing it\n",
      "     |      \n",
      "     |      :return: An enqueue JSON response.\n",
      "     |      \n",
      "     |          .. code-block:: javascript\n",
      "     |      \n",
      "     |             {\n",
      "     |                  \"queued\": 1,\n",
      "     |                  \"updated\": 1,\n",
      "     |                  \"fields\": {\n",
      "     |                      \"status\": \"queued\",\n",
      "     |                      \"status_reason\": \"\",\n",
      "     |                      \"status_message\": \"\",\n",
      "     |                      \"status_changed\": \"2020-02-24T15:05:35.426770+00:00\",\n",
      "     |                      \"last_update\": \"2020-02-24T15:05:35.426770+00:00\",\n",
      "     |                      \"execution.queue\": \"2bd96ab2d9e54b578cc2fb195e52c7cf\"\n",
      "     |                      }\n",
      "     |              }\n",
      "     |      \n",
      "     |          - ``queued``  - The number of Tasks enqueued (an integer or ``null``).\n",
      "     |          - ``updated`` - The number of Tasks updated (an integer or ``null``).\n",
      "     |          - ``fields``\n",
      "     |      \n",
      "     |            - ``status`` - The status of the experiment.\n",
      "     |            - ``status_reason`` - The reason for the last status change.\n",
      "     |            - ``status_message`` - Information about the status.\n",
      "     |            - ``status_changed`` - The last status change date and time (ISO 8601 format).\n",
      "     |            - ``last_update`` - The last Task update time, including Task creation, update, change, or events for this task (ISO 8601 format).\n",
      "     |            - ``execution.queue`` - The ID of the queue where the Task is enqueued. ``null`` indicates not enqueued.\n",
      "     |  \n",
      "     |  get_by_name(task_name) from abc.ABCMeta\n",
      "     |      .. note::\n",
      "     |          This method is deprecated, use :meth:`Task.get_task` instead.\n",
      "     |      \n",
      "     |      Returns the most recent task with the given name from anywhere in the system as a Task object.\n",
      "     |      \n",
      "     |      :param str task_name: The name of the task to search for.\n",
      "     |      \n",
      "     |      :return: Task object of the most recent task with that name.\n",
      "     |  \n",
      "     |  get_num_enqueued_tasks(queue_name=None, queue_id=None) from abc.ABCMeta\n",
      "     |      Get the number of tasks enqueued in a given queue.\n",
      "     |      \n",
      "     |      :param queue_name: The name of the queue. If not specified, then ``queue_id`` must be specified\n",
      "     |      :param queue_id: The ID of the queue. If not specified, then ``queue_name`` must be specified\n",
      "     |      \n",
      "     |      :return: The number of tasks enqueued in the given queue\n",
      "     |  \n",
      "     |  get_task(task_id=None, project_name=None, task_name=None, tags=None, allow_archived=True, task_filter=None) from abc.ABCMeta\n",
      "     |      Get a Task by ID, or project name / task name combination.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      The following code demonstrates calling ``Task.get_task`` to report a scalar to another Task. The output\n",
      "     |      of :meth:`.Logger.report_scalar` from testing is associated with the Task named ``training``. It allows\n",
      "     |      training and testing to run concurrently, because they initialized different Tasks (see :meth:`Task.init`\n",
      "     |      for information about initializing Tasks).\n",
      "     |      \n",
      "     |      The training script:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          # initialize the training Task\n",
      "     |          task = Task.init('myProject', 'training')\n",
      "     |      \n",
      "     |          # do some training\n",
      "     |      \n",
      "     |      The testing script:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          # initialize the testing Task\n",
      "     |          task = Task.init('myProject', 'testing')\n",
      "     |      \n",
      "     |          # get the training Task\n",
      "     |          train_task = Task.get_task(project_name='myProject', task_name='training')\n",
      "     |      \n",
      "     |          # report metrics in the training Task\n",
      "     |          for x in range(10):\n",
      "     |              train_task.get_logger().report_scalar('title', 'series', value=x * 2, iteration=x)\n",
      "     |      \n",
      "     |      :param str task_id: The ID (system UUID) of the experiment to get.\n",
      "     |          If specified, ``project_name`` and ``task_name`` are ignored.\n",
      "     |      :param str project_name: The project name of the Task to get.\n",
      "     |      :param str task_name: The name of the Task within ``project_name`` to get.\n",
      "     |      :param list tags: Filter based on the requested list of tags (strings). To exclude a tag add \"-\" prefix to the\n",
      "     |          tag. Example: ``[\"best\", \"-debug\"]``.\n",
      "     |          The default behaviour is to join all tags with a logical \"OR\" operator.\n",
      "     |          To join all tags with a logical \"AND\" operator instead, use \"__$all\" as the first string, for example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"best\", \"experiment\", \"ever\"]\n",
      "     |      \n",
      "     |          To join all tags with AND, but exclude a tag use \"__$not\" before the excluded tag, for example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"best\", \"experiment\", \"ever\", \"__$not\", \"internal\", \"__$not\", \"test\"]\n",
      "     |      \n",
      "     |          The \"OR\" and \"AND\" operators apply to all tags that follow them until another operator is specified.\n",
      "     |          The NOT operator applies only to the immediately following tag.\n",
      "     |          For example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"a\", \"b\", \"c\", \"__$or\", \"d\", \"__$not\", \"e\", \"__$and\", \"__$or\" \"f\", \"g\"]\n",
      "     |      \n",
      "     |          This example means (\"a\" AND \"b\" AND \"c\" AND (\"d\" OR NOT \"e\") AND (\"f\" OR \"g\")).\n",
      "     |          See https://clear.ml/docs/latest/docs/clearml_sdk/task_sdk/#tag-filters for more information.\n",
      "     |      :param bool allow_archived: Only applicable if *not* using specific ``task_id``,\n",
      "     |          If True (default), allow to return archived Tasks, if False filter out archived Tasks\n",
      "     |      :param bool task_filter: Only applicable if *not* using specific ``task_id``,\n",
      "     |          Pass additional query filters, on top of project/name. See details in Task.get_tasks.\n",
      "     |      \n",
      "     |      :return: The Task specified by ID, or project name / experiment name combination.\n",
      "     |      :rtype: Task\n",
      "     |  \n",
      "     |  get_tasks(task_ids=None, project_name=None, task_name=None, tags=None, allow_archived=True, task_filter=None) from abc.ABCMeta\n",
      "     |      Get a list of Tasks objects matching the queries/filters\n",
      "     |      \n",
      "     |      - A list of specific Task IDs.\n",
      "     |      - Filter Tasks based on specific fields:\n",
      "     |          project name (including partial match), task name (including partial match), tags\n",
      "     |          Apply Additional advanced filtering with `task_filter`\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This function returns the most recent 500 tasks. If you wish to retrieve older tasks\n",
      "     |          use ``Task.query_tasks()``\n",
      "     |      \n",
      "     |      :param list(str) task_ids: The IDs (system UUID) of experiments to get.\n",
      "     |          If ``task_ids`` specified, then ``project_name`` and ``task_name`` are ignored.\n",
      "     |      :param str project_name: The project name of the Tasks to get. To get the experiment\n",
      "     |          in all projects, use the default value of ``None``. (Optional)\n",
      "     |          Use a list of strings for multiple optional project names.\n",
      "     |      :param str task_name: The full name or partial name of the Tasks to match within the specified\n",
      "     |          ``project_name`` (or all projects if ``project_name`` is ``None``).\n",
      "     |          This method supports regular expressions for name matching (if you wish to match special characters and\n",
      "     |          avoid any regex behaviour, use re.escape()). (Optional)\n",
      "     |          To match an exact task name (i.e. not partial matching),\n",
      "     |          add ^/$ at the beginning/end of the string, for example: \"^exact_task_name_here$\"\n",
      "     |      :param list tags: Filter based on the requested list of tags (strings). To exclude a tag add \"-\" prefix to the\n",
      "     |          tag. Example: ``[\"best\", \"-debug\"]``.\n",
      "     |          The default behaviour is to join all tags with a logical \"OR\" operator.\n",
      "     |          To join all tags with a logical \"AND\" operator instead, use \"__$all\" as the first string, for example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"best\", \"experiment\", \"ever\"]\n",
      "     |      \n",
      "     |          To join all tags with AND, but exclude a tag use \"__$not\" before the excluded tag, for example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"best\", \"experiment\", \"ever\", \"__$not\", \"internal\", \"__$not\", \"test\"]\n",
      "     |      \n",
      "     |          The \"OR\" and \"AND\" operators apply to all tags that follow them until another operator is specified.\n",
      "     |          The NOT operator applies only to the immediately following tag.\n",
      "     |          For example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"a\", \"b\", \"c\", \"__$or\", \"d\", \"__$not\", \"e\", \"__$and\", \"__$or\" \"f\", \"g\"]\n",
      "     |      \n",
      "     |          This example means (\"a\" AND \"b\" AND \"c\" AND (\"d\" OR NOT \"e\") AND (\"f\" OR \"g\")).\n",
      "     |          See https://clear.ml/docs/latest/docs/clearml_sdk/task_sdk/#tag-filters for more information.\n",
      "     |      :param bool allow_archived: If True (default), allow to return archived Tasks, if False filter out archived Tasks\n",
      "     |      :param dict task_filter: filter and order Tasks.\n",
      "     |          See :class:`.backend_api.service.v?.tasks.GetAllRequest` for details; the ? needs to be replaced by the appropriate version.\n",
      "     |      \n",
      "     |        - ``parent`` - (str) filter by parent task-id matching\n",
      "     |        - ``search_text`` - (str) free text search (in task fields comment/name/id)\n",
      "     |        - ``status`` - List[str] List of valid statuses. Options are: \"created\", \"queued\", \"in_progress\", \"stopped\", \"published\", \"publishing\", \"closed\", \"failed\", \"completed\", \"unknown\"\n",
      "     |        - ``type`` - List[str] List of valid task types. Options are: 'training', 'testing', 'inference', 'data_processing', 'application', 'monitor', 'controller', 'optimizer', 'service', 'qc'. 'custom'\n",
      "     |        - ``user`` - List[str] Filter based on Task's user owner, provide list of valid user IDs.\n",
      "     |        - ``order_by`` - List[str] List of field names to order by. When ``search_text`` is used. Use '-' prefix to specify descending order. Optional, recommended when using page. Example: ``order_by=['-last_update']``\n",
      "     |        - ``_all_`` - dict(fields=[], pattern='')  Match string `pattern` (regular expression) appearing in All `fields`. Example: dict(fields=['script.repository'], pattern='github.com/user')\n",
      "     |        - ``_any_`` - dict(fields=[], pattern='')  Match string `pattern` (regular expression) appearing in Any of the `fields`. Example: dict(fields=['comment', 'name'], pattern='my comment')\n",
      "     |        - Examples - ``{'status': ['stopped'], 'order_by': [\"-last_update\"]}`` , ``{'order_by'=['-last_update'], '_all_'=dict(fields=['script.repository'], pattern='github.com/user'))``\n",
      "     |      \n",
      "     |      :return: The Tasks specified by the parameter combinations (see the parameters).\n",
      "     |      :rtype: List[Task]\n",
      "     |  \n",
      "     |  import_offline_session(session_folder_zip, previous_task_id=None, iteration_offset=0) from abc.ABCMeta\n",
      "     |      Upload an offline session (execution) of a Task.\n",
      "     |      Full Task execution includes repository details, installed packages, artifacts, logs, metric and debug samples.\n",
      "     |      This function may also be used to continue a previously executed task with a task executed offline.\n",
      "     |      \n",
      "     |      :param session_folder_zip: Path to a folder containing the session, or zip-file of the session folder.\n",
      "     |      :param previous_task_id: Task ID of the task you wish to continue with this offline session.\n",
      "     |      :param iteration_offset: Reporting of the offline session will be offset with the\n",
      "     |          number specified by this parameter. Useful for avoiding overwriting metrics.\n",
      "     |      \n",
      "     |      :return: Newly created task ID or the ID of the continued task (previous_task_id)\n",
      "     |  \n",
      "     |  import_task(task_data, target_task=None, update=False) from abc.ABCMeta\n",
      "     |      Import (create) Task from previously exported Task configuration (see Task.export_task)\n",
      "     |      Can also be used to edit/update an existing Task (by passing `target_task` and `update=True`).\n",
      "     |      \n",
      "     |      :param task_data: dictionary of a Task's configuration\n",
      "     |      :param target_task: Import task_data into an existing Task. Can be either task_id (str) or Task object.\n",
      "     |      :param update: If True, merge task_data with current Task configuration.\n",
      "     |      :return: return True if Task was imported/updated\n",
      "     |  \n",
      "     |  init(project_name=None, task_name=None, task_type=<TaskTypes.training: 'training'>, tags=None, reuse_last_task_id=True, continue_last_task=False, output_uri=None, auto_connect_arg_parser=True, auto_connect_frameworks=True, auto_resource_monitoring=True, auto_connect_streams=True, deferred_init=False) from abc.ABCMeta\n",
      "     |      Creates a new Task (experiment) if:\n",
      "     |      \n",
      "     |      - The Task never ran before. No Task with the same ``task_name`` and ``project_name`` is stored in\n",
      "     |        **ClearML Server**.\n",
      "     |      - The Task has run before (the same ``task_name`` and ``project_name``), and (a) it stored models and / or\n",
      "     |        artifacts, or (b) its status is Published , or (c) it is Archived.\n",
      "     |      - A new Task is forced by calling ``Task.init`` with ``reuse_last_task_id=False``.\n",
      "     |      \n",
      "     |      Otherwise, the already initialized Task object for the same ``task_name`` and ``project_name`` is returned,\n",
      "     |      or, when being executed remotely on a clearml-agent, the task returned is the existing task from the backend.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          To reference another Task, instead of initializing the same Task more than once, call\n",
      "     |          :meth:`Task.get_task`. For example, to \"share\" the same experiment in more than one script,\n",
      "     |          call ``Task.get_task``. See the ``Task.get_task`` method for an example.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      The first time the following code runs, it will create a new Task. The status will be Completed.\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          from clearml import Task\n",
      "     |          task = Task.init('myProject', 'myTask')\n",
      "     |      \n",
      "     |      If this code runs again, it will not create a new Task. It does not store a model or artifact,\n",
      "     |      it is not Published (its status Completed) , it was not Archived, and a new Task is not forced.\n",
      "     |      \n",
      "     |      If the Task is Published or Archived, and run again, it will create a new Task with a new Task ID.\n",
      "     |      \n",
      "     |      The following code will create a new Task every time it runs, because it stores an artifact.\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          task = Task.init('myProject', 'myOtherTask')\n",
      "     |      \n",
      "     |          d = {'a': '1'}\n",
      "     |          task.upload_artifact('myArtifact', d)\n",
      "     |      \n",
      "     |      :param str project_name: The name of the project in which the experiment will be created. If the project does\n",
      "     |          not exist, it is created. If ``project_name`` is ``None``, the repository name is used. (Optional)\n",
      "     |      :param str task_name: The name of Task (experiment). If ``task_name`` is ``None``, the Python experiment\n",
      "     |          script's file name is used. (Optional)\n",
      "     |      :param TaskTypes task_type: The task type. Valid task types:\n",
      "     |      \n",
      "     |          - ``TaskTypes.training`` (default)\n",
      "     |          - ``TaskTypes.testing``\n",
      "     |          - ``TaskTypes.inference``\n",
      "     |          - ``TaskTypes.data_processing``\n",
      "     |          - ``TaskTypes.application``\n",
      "     |          - ``TaskTypes.monitor``\n",
      "     |          - ``TaskTypes.controller``\n",
      "     |          - ``TaskTypes.optimizer``\n",
      "     |          - ``TaskTypes.service``\n",
      "     |          - ``TaskTypes.qc``\n",
      "     |          - ``TaskTypes.custom``\n",
      "     |      \n",
      "     |      :param tags: Add a list of tags (str) to the created Task. For example: tags=['512x512', 'yolov3']\n",
      "     |      :param bool reuse_last_task_id: Force a new Task (experiment) with a previously used Task ID,\n",
      "     |          and the same project and Task name. If the previously executed Task has artifacts or models, it will not be\n",
      "     |          reused (overwritten), and a new Task will be created. When a Task is reused, the previous execution outputs\n",
      "     |          are deleted, including console outputs and logs. The values are:\n",
      "     |      \n",
      "     |        - ``True`` - Reuse the last  Task ID. (default)\n",
      "     |        - ``False`` - Force a new Task (experiment).\n",
      "     |        - A string - You can also specify a Task ID (string) to be reused, instead of the cached ID based on the project/name combination.\n",
      "     |      \n",
      "     |      :param bool continue_last_task: Continue the execution of a previously executed Task (experiment). When\n",
      "     |          continuing the executing of a previously executed Task,\n",
      "     |          all previous artifacts / models / logs remain intact.\n",
      "     |          New logs will continue iteration/step based on the previous-execution maximum iteration value.\n",
      "     |          For example, The last train/loss scalar reported was iteration 100, the next report will be iteration 101.\n",
      "     |          The values are:\n",
      "     |      \n",
      "     |        - ``True`` - Continue the last Task ID. Specified explicitly by reuse_last_task_id or implicitly with the same logic as reuse_last_task_id\n",
      "     |        - ``False`` - Overwrite the execution of previous Task  (default).\n",
      "     |        - A string - You can also specify a Task ID (string) to be continued. This is equivalent to `continue_last_task=True` and `reuse_last_task_id=a_task_id_string`.\n",
      "     |        - An integer - Specify initial iteration offset (override the auto automatic last_iteration_offset). Pass 0, to disable the automatic last_iteration_offset or specify a different initial offset. You can specify a Task ID to be used with `reuse_last_task_id='task_id_here'`\n",
      "     |      \n",
      "     |      :param str output_uri: The default location for output models and other artifacts. If True, the default\n",
      "     |          files_server will be used for model storage. In the default location, ClearML creates a subfolder for the\n",
      "     |          output. If set to False, local runs will not upload output models and artifacts,\n",
      "     |          and remote runs will not use any default values provided using ``default_output_uri``.\n",
      "     |          The subfolder structure is the following: `<output destination name> / <project name> / <task name>.<Task ID>`.\n",
      "     |          Note that for cloud storage, you must install the **ClearML** package for your cloud storage type,\n",
      "     |          and then configure your storage credentials. For detailed information, see \"Storage\" in the ClearML\n",
      "     |          Documentation.\n",
      "     |          The following are examples of ``output_uri`` values for the supported locations:\n",
      "     |      \n",
      "     |        - A shared folder: ``/mnt/share/folder``\n",
      "     |        - S3: ``s3://bucket/folder``\n",
      "     |        - Google Cloud Storage: ``gs://bucket-name/folder``\n",
      "     |        - Azure Storage: ``azure://company.blob.core.windows.net/folder/``\n",
      "     |        - Default file server: True\n",
      "     |      \n",
      "     |      :param auto_connect_arg_parser: Automatically connect an argparse object to the Task. Supported argument\n",
      "     |          parser packages are: argparse, click, python-fire, jsonargparse. The values are:\n",
      "     |      \n",
      "     |        - ``True`` - Automatically connect. (default)\n",
      "     |        - ``False`` - Do not automatically connect.\n",
      "     |        - A dictionary - In addition to a boolean, you can use a dictionary for fined grained control of connected\n",
      "     |            arguments. The dictionary keys are argparse variable names and the values are booleans.\n",
      "     |            The ``False`` value excludes the specified argument from the Task's parameter section.\n",
      "     |            Keys missing from the dictionary default to ``True``, you can change it to be ``False`` by adding\n",
      "     |            ``*`` key as ``False`` to the dictionary.\n",
      "     |            An empty dictionary defaults to ``False``.\n",
      "     |      \n",
      "     |            For example:\n",
      "     |      \n",
      "     |            .. code-block:: py\n",
      "     |      \n",
      "     |               auto_connect_arg_parser={\"do_not_include_me\": False, }\n",
      "     |      \n",
      "     |            .. code-block:: py\n",
      "     |      \n",
      "     |               auto_connect_arg_parser={\"only_include_me\": True, \"*\": False}\n",
      "     |      \n",
      "     |            .. note::\n",
      "     |             To manually connect an argparse, use :meth:`Task.connect`.\n",
      "     |      \n",
      "     |      :param auto_connect_frameworks: Automatically connect frameworks This includes patching MatplotLib, XGBoost,\n",
      "     |          scikit-learn, Keras callbacks, and TensorBoard/X to serialize plots, graphs, and the model location to\n",
      "     |          the **ClearML Server** (backend), in addition to original output destination.\n",
      "     |          The values are:\n",
      "     |      \n",
      "     |        - ``True`` - Automatically connect (default)\n",
      "     |        - ``False`` - Do not automatically connect\n",
      "     |        - A dictionary - In addition to a boolean, you can use a dictionary for fined grained control of connected\n",
      "     |            frameworks. The dictionary keys are frameworks and the values are booleans, other dictionaries used for\n",
      "     |            finer control or wildcard strings.\n",
      "     |            In case of wildcard strings, the local path of a model file has to match at least one wildcard to be\n",
      "     |            saved/loaded by ClearML. Example: {'pytorch' : '*.pt', 'tensorflow': ['*.h5', '*']}\n",
      "     |            Keys missing from the dictionary default to ``True``, and an empty dictionary defaults to ``False``.\n",
      "     |            Supported keys for finer control: {'tensorboard': {'report_hparams': bool}}  # whether to report TensorBoard hyperparameters\n",
      "     |      \n",
      "     |            For example:\n",
      "     |      \n",
      "     |            .. code-block:: py\n",
      "     |      \n",
      "     |               auto_connect_frameworks={\n",
      "     |                   'matplotlib': True, 'tensorflow': ['*.hdf5, 'something_else*], 'tensorboard': True,\n",
      "     |                   'pytorch': ['*.pt'], 'xgboost': True, 'scikit': True, 'fastai': True,\n",
      "     |                   'lightgbm': True, 'hydra': True, 'detect_repository': True, 'tfdefines': True,\n",
      "     |                   'joblib': True, 'megengine': True, 'catboost': True, 'gradio': True\n",
      "     |               }\n",
      "     |      \n",
      "     |            .. code-block:: py\n",
      "     |      \n",
      "     |                auto_connect_frameworks={'tensorboard': {'report_hparams': False}}\n",
      "     |      \n",
      "     |      :param bool auto_resource_monitoring: Automatically create machine resource monitoring plots\n",
      "     |          These plots appear in the **ClearML Web-App (UI)**, **RESULTS** tab, **SCALARS** sub-tab,\n",
      "     |          with a title of **:resource monitor:**.\n",
      "     |          The values are:\n",
      "     |      \n",
      "     |        - ``True`` - Automatically create resource monitoring plots. (default)\n",
      "     |        - ``False`` - Do not automatically create.\n",
      "     |        - Class Type - Create ResourceMonitor object of the specified class type.\n",
      "     |      \n",
      "     |      :param auto_connect_streams: Control the automatic logging of stdout and stderr.\n",
      "     |          The values are:\n",
      "     |      \n",
      "     |        - ``True`` - Automatically connect (default)\n",
      "     |        -  ``False`` - Do not automatically connect\n",
      "     |        - A dictionary - In addition to a boolean, you can use a dictionary for fined grained control of stdout and\n",
      "     |            stderr. The dictionary keys are 'stdout' , 'stderr' and 'logging', the values are booleans.\n",
      "     |            Keys missing from the dictionary default to ``False``, and an empty dictionary defaults to ``False``.\n",
      "     |            Notice, the default behaviour is logging stdout/stderr. The `logging` module is logged as a by product\n",
      "     |            of the stderr logging\n",
      "     |      \n",
      "     |            For example:\n",
      "     |      \n",
      "     |            .. code-block:: py\n",
      "     |      \n",
      "     |               auto_connect_streams={'stdout': True, 'stderr': True, 'logging': False}\n",
      "     |      \n",
      "     |      :param deferred_init: (default: False) Wait for Task to be fully initialized (regular behaviour).\n",
      "     |          ** BETA feature! use with care **.\n",
      "     |      \n",
      "     |          If set to True, `Task.init` function returns immediately and all initialization / communication\n",
      "     |          to the clearml-server is running in a background thread. The returned object is\n",
      "     |          a full proxy to the regular Task object, hence everything will be working as expected.\n",
      "     |          Default behaviour can be controlled with: ``CLEARML_DEFERRED_TASK_INIT=1``. Notes:\n",
      "     |      \n",
      "     |        - Any access to the returned proxy `Task` object will essentially wait for the `Task.init` to be completed.\n",
      "     |            For example: `print(task.name)` will wait for `Task.init` to complete in the\n",
      "     |            background and then return the `name` property of the task original object\n",
      "     |        - Before `Task.init` completes in the background, auto-magic logging (console/metric) might be missed\n",
      "     |        - If running via an agent, this argument is ignored, and Task init is called synchronously (default)\n",
      "     |      \n",
      "     |      :return: The main execution Task (Task context)\n",
      "     |      :rtype: Task\n",
      "     |  \n",
      "     |  is_offline() from abc.ABCMeta\n",
      "     |      Return offline-mode state, If in offline-mode, no communication to the backend is enabled.\n",
      "     |      \n",
      "     |      :return: boolean offline-mode state\n",
      "     |  \n",
      "     |  query_tasks(project_name=None, task_name=None, tags=None, additional_return_fields=None, task_filter=None) from abc.ABCMeta\n",
      "     |      Get a list of Tasks ID matching the specific query/filter.\n",
      "     |      Notice, if `additional_return_fields` is specified, returns a list of\n",
      "     |      dictionaries with requested fields (dict per Task)\n",
      "     |      \n",
      "     |      :param str project_name: The project name of the Tasks to get. To get the experiment\n",
      "     |          in all projects, use the default value of ``None``. (Optional)\n",
      "     |          Use a list of strings for multiple optional project names.\n",
      "     |      :param str task_name: The full name or partial name of the Tasks to match within the specified\n",
      "     |          ``project_name`` (or all projects if ``project_name`` is ``None``).\n",
      "     |          This method supports regular expressions for name matching (if you wish to match special characters and\n",
      "     |          avoid any regex behaviour, use re.escape()). (Optional)\n",
      "     |      :param str project_name: project name (str) the task belongs to (use None for all projects)\n",
      "     |      :param str task_name: task name (str) within the selected project\n",
      "     |          Return any partial match of task_name, regular expressions matching is also supported.\n",
      "     |          If None is passed, returns all tasks within the project\n",
      "     |      :param list tags: Filter based on the requested list of tags (strings).\n",
      "     |          To exclude a tag add \"-\" prefix to the tag. Example: ``[\"best\", \"-debug\"]``.\n",
      "     |          The default behaviour is to join all tags with a logical \"OR\" operator.\n",
      "     |          To join all tags with a logical \"AND\" operator instead, use \"__$all\" as the first string, for example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"best\", \"experiment\", \"ever\"]\n",
      "     |      \n",
      "     |          To join all tags with AND, but exclude a tag use \"__$not\" before the excluded tag, for example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"best\", \"experiment\", \"ever\", \"__$not\", \"internal\", \"__$not\", \"test\"]\n",
      "     |      \n",
      "     |          The \"OR\" and \"AND\" operators apply to all tags that follow them until another operator is specified.\n",
      "     |          The NOT operator applies only to the immediately following tag.\n",
      "     |          For example:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              [\"__$all\", \"a\", \"b\", \"c\", \"__$or\", \"d\", \"__$not\", \"e\", \"__$and\", \"__$or\" \"f\", \"g\"]\n",
      "     |      \n",
      "     |          This example means (\"a\" AND \"b\" AND \"c\" AND (\"d\" OR NOT \"e\") AND (\"f\" OR \"g\")).\n",
      "     |          See https://clear.ml/docs/latest/docs/clearml_sdk/task_sdk/#tag-filters for more information.\n",
      "     |      :param list additional_return_fields: Optional, if not provided return a list of Task IDs.\n",
      "     |          If provided return dict per Task with the additional requested fields.\n",
      "     |          Example: ``returned_fields=['last_updated', 'user', 'script.repository']`` will return a list of dict:\n",
      "     |          ``[{'id': 'task_id', 'last_update': datetime.datetime(), 'user': 'user_id', 'script.repository': 'https://github.com/user/'}, ]``\n",
      "     |      :param dict task_filter: filter and order Tasks.\n",
      "     |          See :class:`.backend_api.service.v?.tasks.GetAllRequest` for details; the ? needs to be replaced by the appropriate version.\n",
      "     |      \n",
      "     |        - ``parent`` - (str) filter by parent task-id matching\n",
      "     |        - ``search_text`` - (str) free text search (in task fields comment/name/id)\n",
      "     |        - ``status`` - List[str] List of valid statuses. Options are: \"created\", \"queued\", \"in_progress\", \"stopped\", \"published\", \"publishing\", \"closed\", \"failed\", \"completed\", \"unknown\"\n",
      "     |        - ``type`` - List[Union[str, TaskTypes]] List of valid task types. Options are: 'training', 'testing', 'inference', 'data_processing', 'application', 'monitor', 'controller', 'optimizer', 'service', 'qc'. 'custom'\n",
      "     |        - ``user`` - List[str] Filter based on Task's user owner, provide list of valid user IDs.\n",
      "     |        - ``order_by`` - List[str] List of field names to order by. When search_text is used. Use '-' prefix to specify descending order. Optional, recommended when using page. Example: ``order_by=['-last_update']``\n",
      "     |        - ``_all_`` - dict(fields=[], pattern='')  Match string ``pattern`` (regular expression) appearing in All `fields`. ``dict(fields=['script.repository'], pattern='github.com/user')``\n",
      "     |        - ``_any_`` - dict(fields=[], pattern='')  Match string `pattern` (regular expression) appearing in Any of the `fields`. `dict(fields=['comment', 'name'], pattern='my comment')`\n",
      "     |        - Examples: ``{'status': ['stopped'], 'order_by': [\"-last_update\"]}``, ``{'order_by'=['-last_update'], '_all_'=dict(fields=['script.repository'], pattern='github.com/user')}``\n",
      "     |      \n",
      "     |      :return: The Tasks specified by the parameter combinations (see the parameters).\n",
      "     |  \n",
      "     |  set_credentials(api_host=None, web_host=None, files_host=None, key=None, secret=None, store_conf_file=False) from abc.ABCMeta\n",
      "     |      Set new default **ClearML Server** (backend) host and credentials.\n",
      "     |      \n",
      "     |      These credentials will be overridden by either OS environment variables, or the ClearML configuration\n",
      "     |      file, ``clearml.conf``.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |         Credentials must be set before initializing a Task object.\n",
      "     |      \n",
      "     |      For example, to set credentials for a remote computer:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          Task.set_credentials(\n",
      "     |              api_host='http://localhost:8008', web_host='http://localhost:8080', files_host='http://localhost:8081',\n",
      "     |              key='optional_credentials',  secret='optional_credentials'\n",
      "     |          )\n",
      "     |          task = Task.init('project name', 'experiment name')\n",
      "     |      \n",
      "     |      :param str api_host: The API server url. For example, ``host='http://localhost:8008'``\n",
      "     |      :param str web_host: The Web server url. For example, ``host='http://localhost:8080'``\n",
      "     |      :param str files_host: The file server url. For example, ``host='http://localhost:8081'``\n",
      "     |      :param str key: The user key (in the key/secret pair). For example, ``key='thisisakey123'``\n",
      "     |      :param str secret: The user secret (in the key/secret pair). For example, ``secret='thisisseceret123'``\n",
      "     |      :param bool store_conf_file: If True, store the current configuration into the ~/clearml.conf file.\n",
      "     |          If the configuration file exists, no change will be made (outputs a warning).\n",
      "     |          Not applicable when running remotely (i.e. clearml-agent).\n",
      "     |  \n",
      "     |  set_offline(offline_mode=False) from abc.ABCMeta\n",
      "     |      Set offline mode, where all data and logs are stored into local folder, for later transmission\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          `Task.set_offline` can't move the same task from offline to online, nor can it be applied before `Task.create`.\n",
      "     |          See below an example of **incorrect** usage of `Task.set_offline`:\n",
      "     |      \n",
      "     |          ```\n",
      "     |          from clearml import Task\n",
      "     |      \n",
      "     |          Task.set_offline(True)\n",
      "     |          task = Task.create(project_name='DEBUG', task_name=\"offline\")\n",
      "     |          # ^^^ an error or warning is raised, saying that Task.set_offline(True)\n",
      "     |          #     is supported only for `Task.init`\n",
      "     |          Task.set_offline(False)\n",
      "     |          # ^^^ an error or warning is raised, saying that running Task.set_offline(False)\n",
      "     |          #     while the current task is not closed is not supported\n",
      "     |      \n",
      "     |          data = task.export_task()\n",
      "     |      \n",
      "     |          imported_task = Task.import_task(task_data=data)\n",
      "     |          ```\n",
      "     |      \n",
      "     |          The correct way to use `Task.set_offline` can be seen in the following example:\n",
      "     |      \n",
      "     |          ```\n",
      "     |          from clearml import Task\n",
      "     |      \n",
      "     |          Task.set_offline(True)\n",
      "     |          task = Task.init(project_name='DEBUG', task_name=\"offline\")\n",
      "     |          task.upload_artifact(\"large_artifact\", \"test_string\")\n",
      "     |          task.close()\n",
      "     |          Task.set_offline(False)\n",
      "     |      \n",
      "     |          imported_task = Task.import_offline_session(task.get_offline_mode_folder())\n",
      "     |          ```\n",
      "     |      \n",
      "     |      :param offline_mode: If True, offline-mode is turned on, and no communication to the backend is enabled.\n",
      "     |      :return:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  artifacts\n",
      "     |      A read-only dictionary of Task artifacts (name, artifact).\n",
      "     |      \n",
      "     |      :return: The artifacts.\n",
      "     |  \n",
      "     |  last_worker\n",
      "     |      ID of last worker that handled the task.\n",
      "     |      \n",
      "     |      :return: The worker ID.\n",
      "     |  \n",
      "     |  logger\n",
      "     |      Get a Logger object for reporting, for this task context. You can view all Logger report output associated with\n",
      "     |      the Task for which this method is called, including metrics, plots, text, tables, and images, in the\n",
      "     |      **ClearML Web-App (UI)**.\n",
      "     |      \n",
      "     |      :return: The Logger object for the current Task (experiment).\n",
      "     |  \n",
      "     |  models\n",
      "     |      Read-only dictionary of the Task's loaded/stored models.\n",
      "     |      \n",
      "     |      :return: A dictionary-like object with \"input\"/\"output\" keys and input/output properties, pointing to a\n",
      "     |          list-like object containing Model objects. Each list-like object also acts as a dictionary, mapping\n",
      "     |          model name to an appropriate model instance.\n",
      "     |      \n",
      "     |          Get input/output models:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              task.models.input\n",
      "     |              task.models[\"input\"]\n",
      "     |      \n",
      "     |              task.models.output\n",
      "     |              task.models[\"output\"]\n",
      "     |      \n",
      "     |          Get the last output model:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              task.models.output[-1]\n",
      "     |      \n",
      "     |          Get a model by name:\n",
      "     |      \n",
      "     |          .. code-block:: py\n",
      "     |      \n",
      "     |              task.models.output[\"model name\"]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_uri\n",
      "     |      The storage / output url for this task. This is the default location for output models and other artifacts.\n",
      "     |      \n",
      "     |      :return: The url string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  NotSet = <object object>\n",
      "     |  \n",
      "     |  TaskTypes = <enum 'TaskTypes'>\n",
      "     |      An enumeration.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from clearml.backend_interface.task.task.Task:\n",
      "     |  \n",
      "     |  completed(self, ignore_errors=True)\n",
      "     |      .. note:: Deprecated, use mark_completed(...) instead\n",
      "     |  \n",
      "     |  delete_artifacts(self, artifact_names, raise_on_errors=True, delete_from_storage=True)\n",
      "     |      Delete a list of artifacts, by artifact name, from the Task.\n",
      "     |      \n",
      "     |      :param list artifact_names: list of artifact names\n",
      "     |      :param bool raise_on_errors: if True, do not suppress connectivity related exceptions\n",
      "     |      :param bool delete_from_storage: If True, try to delete the actual\n",
      "     |          file from the external storage (e.g. S3, GS, Azure, File Server etc.)\n",
      "     |      \n",
      "     |      :return: True if successful\n",
      "     |  \n",
      "     |  delete_parameter(self, name, force=False)\n",
      "     |      Delete a parameter by its full name Section/name.\n",
      "     |      \n",
      "     |      :param name: Parameter name in full, i.e. Section/name. For example, 'Args/batch_size'\n",
      "     |      :param force: If set to True then both new and running task hyper params can be deleted.\n",
      "     |          Otherwise only the new task ones. Default is False\n",
      "     |      :return: True if the parameter was deleted successfully\n",
      "     |  \n",
      "     |  get_all_reported_scalars(self, x_axis='iter')\n",
      "     |      Return a nested dictionary for the all scalar graphs, containing all the registered samples,\n",
      "     |      where the first key is the graph title and the second is the series name.\n",
      "     |      Value is a dict with 'x': values and 'y': values.\n",
      "     |      To fetch downsampled scalar values, please see the :meth:`Task.get_reported_scalars`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         This call is not cached, any call will retrieve all the scalar reports from the back-end.\n",
      "     |         If the Task has many scalars reported, it might take long for the call to return.\n",
      "     |      \n",
      "     |      :param str x_axis: scalar x_axis, possible values:\n",
      "     |          'iter': iteration (default), 'timestamp': timestamp as milliseconds since epoch, 'iso_time': absolute time\n",
      "     |      :return: dict: Nested scalar graphs: dict[title(str), dict[series(str), dict[axis(str), list(float)]]]\n",
      "     |  \n",
      "     |  get_archived(self)\n",
      "     |      Return the Archive state of the Task\n",
      "     |      \n",
      "     |      :return: If True, the Task is archived, otherwise it is not.\n",
      "     |  \n",
      "     |  get_base_docker(self)\n",
      "     |      Get the base Docker command (image) that is set for this experiment.\n",
      "     |  \n",
      "     |  get_configuration_object(self, name)\n",
      "     |      Get the Task's configuration object section as a blob of text\n",
      "     |      Use only for automation (externally), otherwise use `Task.connect_configuration`.\n",
      "     |      \n",
      "     |      :param str name: Configuration section name\n",
      "     |      :return: The Task's configuration as a text blob (unconstrained text string)\n",
      "     |          return None if configuration name is not valid\n",
      "     |  \n",
      "     |  get_configuration_object_as_dict(self, name)\n",
      "     |      Get the Task's configuration object section as parsed dictionary\n",
      "     |      Parsing supports JSON and HOCON, otherwise parse manually with `get_configuration_object()`\n",
      "     |      Use only for automation (externally), otherwise use `Task.connect_configuration`.\n",
      "     |      \n",
      "     |      :param str name: Configuration section name\n",
      "     |      :return: The Task's configuration as a parsed dict.\n",
      "     |          return None if configuration name is not valid\n",
      "     |  \n",
      "     |  get_configuration_objects(self)\n",
      "     |      Get the Task's configuration object section as a blob of text\n",
      "     |      Use only for automation (externally), otherwise use `Task.connect_configuration`.\n",
      "     |      \n",
      "     |      :return: The Task's configurations as a dict (config name as key) and text blob as value (unconstrained text\n",
      "     |          string)\n",
      "     |  \n",
      "     |  get_labels_enumeration(self)\n",
      "     |      Get the label enumeration dictionary label enumeration dictionary of string (label) to integer (value) pairs.\n",
      "     |      \n",
      "     |      :return: A dictionary containing the label enumeration.\n",
      "     |  \n",
      "     |  get_model_design(self)\n",
      "     |      Get the model configuration as blob of text.\n",
      "     |      \n",
      "     |      :return: The model configuration as blob of text.\n",
      "     |  \n",
      "     |  get_offline_mode_folder(self)\n",
      "     |      Return the folder where all the task outputs and logs are stored in the offline session.\n",
      "     |      :return: Path object, local folder, later to be used with `report_offline_session()`\n",
      "     |  \n",
      "     |  get_output_log_web_page(self)\n",
      "     |      Return the Task results & outputs web page address.\n",
      "     |      For example: https://demoapp.demo.clear.ml/projects/216431/experiments/60763e04/output/log\n",
      "     |      \n",
      "     |      :return: http/s URL link.\n",
      "     |  \n",
      "     |  get_parameter(self, name, default=None, cast=False)\n",
      "     |      Get a value for a parameter.\n",
      "     |      \n",
      "     |      :param name: Parameter name\n",
      "     |      :param default: Default value\n",
      "     |      :param cast: If value is found, cast to original type. If False, return string.\n",
      "     |      :return: The Parameter value (or default value if parameter is not defined).\n",
      "     |  \n",
      "     |  get_parameters(self, backwards_compatibility=True, cast=False)\n",
      "     |      Get the parameters for a Task. This method returns a complete group of key-value parameter pairs, but does not\n",
      "     |      support parameter descriptions (the result is a dictionary of key-value pairs).\n",
      "     |      Notice the returned parameter dict is flat:\n",
      "     |      i.e. {'Args/param': 'value'} is the argument \"param\" from section \"Args\"\n",
      "     |      \n",
      "     |      :param backwards_compatibility: If True (default), parameters without section name\n",
      "     |          (API version < 2.9, clearml-server < 0.16) will be at dict root level.\n",
      "     |          If False, parameters without section name, will be nested under \"Args/\" key.\n",
      "     |      :param cast: If True, cast the parameter to the original type. Default False,\n",
      "     |          values are returned in their string representation\n",
      "     |      \n",
      "     |      :return: dict of the task parameters, all flattened to key/value.\n",
      "     |          Different sections with key prefix \"section/\"\n",
      "     |  \n",
      "     |  get_project_name(self)\n",
      "     |      Get the current Task's project name.\n",
      "     |  \n",
      "     |  get_project_object(self)\n",
      "     |      Get the current Task's project as a python object.\n",
      "     |  \n",
      "     |  get_random_seed(self)\n",
      "     |  \n",
      "     |  get_reported_console_output(self, number_of_reports=1)\n",
      "     |      Return a list of console outputs reported by the Task. Retrieved outputs are the most updated console outputs.\n",
      "     |      \n",
      "     |      :param int number_of_reports: The number of reports to return. The default value is ``1``, indicating the\n",
      "     |          last (most updated) console output\n",
      "     |      :return: A list of strings, each entry corresponds to one report.\n",
      "     |  \n",
      "     |  get_reported_plots(self, max_iterations=None)\n",
      "     |      Return a list of all the plots reported for this Task,\n",
      "     |      Notice the plot data is plotly compatible.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         This call is not cached, any call will retrieve all the plot reports from the back-end.\n",
      "     |         If the Task has many plots reported, it might take long for the call to return.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |        [{\n",
      "     |          \"timestamp\": 1636921296370,\n",
      "     |          \"type\": \"plot\",\n",
      "     |          \"task\": \"0ce5e89bbe484f428e43e767f1e2bb11\",\n",
      "     |          \"iter\": 0,\n",
      "     |          \"metric\": \"Manual Reporting\",\n",
      "     |          \"variant\": \"Just a plot\",\n",
      "     |          \"plot_str\": \"{'data': [{'type': 'scatter', 'mode': 'markers', 'name': null,\n",
      "     |                                  'x': [0.2620246750155817], 'y': [0.2620246750155817]}]}\",\n",
      "     |          \"@timestamp\": \"2021-11-14T20:21:42.387Z\",\n",
      "     |          \"worker\": \"machine-ml\",\n",
      "     |          \"plot_len\": 6135,\n",
      "     |        },]\n",
      "     |      :param int max_iterations: Maximum number of historic plots (iterations from end) to return.\n",
      "     |      :return: list: List of dicts, each one represents a single plot\n",
      "     |  \n",
      "     |  get_reported_scalars(self, max_samples=0, x_axis='iter')\n",
      "     |      Return a nested dictionary for the scalar graphs,\n",
      "     |      where the first key is the graph title and the second is the series name.\n",
      "     |      Value is a dict with 'x': values and 'y': values\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         This call is not cached, any call will retrieve all the scalar reports from the back-end.\n",
      "     |         If the Task has many scalars reported, it might take long for the call to return.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |         Calling this method will return potentially downsampled scalars. The maximum number of returned samples is 5000.\n",
      "     |         Even when setting `max_samples` to a value larger than 5000, it will be limited to at most 5000 samples.\n",
      "     |         To fetch all scalar values, please see the :meth:`Task.get_all_reported_scalars`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |        {\"title\": {\"series\": {\n",
      "     |                    \"x\": [0, 1 ,2],\n",
      "     |                    \"y\": [10, 11 ,12]\n",
      "     |        }}}\n",
      "     |      \n",
      "     |      :param int max_samples: Maximum samples per series to return. Default is 0 returning up to 5000 samples.\n",
      "     |          With sample limit, average scalar values inside sampling window.\n",
      "     |      :param str x_axis: scalar x_axis, possible values:\n",
      "     |          'iter': iteration (default), 'timestamp': timestamp as milliseconds since epoch, 'iso_time': absolute time\n",
      "     |      :return: dict: Nested scalar graphs: dict[title(str), dict[series(str), dict[axis(str), list(float)]]]\n",
      "     |  \n",
      "     |  get_reported_single_value(self, name)\n",
      "     |      Get a single reported value, identified by its name. Note that this function calls\n",
      "     |      `Task.get_reported_single_values`.\n",
      "     |      \n",
      "     |      :param name: The name of the reported value\n",
      "     |      \n",
      "     |      :return: The actual value of the reported value, if found. Otherwise, returns None\n",
      "     |  \n",
      "     |  get_reported_single_values(self)\n",
      "     |      Get all reported single values as a dictionary, where the keys are the names of the values\n",
      "     |      and the values of the dictionary are the actual reported values.\n",
      "     |      \n",
      "     |      :return: A dict containing the reported values\n",
      "     |  \n",
      "     |  get_status(self)\n",
      "     |      Return The task status without refreshing the entire Task object (only the status property)\n",
      "     |      \n",
      "     |      TaskStatusEnum: [\"created\", \"in_progress\", \"stopped\", \"closed\", \"failed\", \"completed\",\n",
      "     |      \"queued\", \"published\", \"publishing\", \"unknown\"]\n",
      "     |      \n",
      "     |      :return: str: Task status as string (TaskStatusEnum)\n",
      "     |  \n",
      "     |  get_status_message(self)\n",
      "     |      Return The task status without refreshing the entire Task object (only the status property)\n",
      "     |      Return also the last message coupled with the status change\n",
      "     |      \n",
      "     |      Task Status options: [\"created\", \"in_progress\", \"stopped\", \"closed\", \"failed\", \"completed\",\n",
      "     |      \"queued\", \"published\", \"publishing\", \"unknown\"]\n",
      "     |      Message: is a string\n",
      "     |      \n",
      "     |      :return: (Task status as string, last message)\n",
      "     |  \n",
      "     |  get_system_tags(self)\n",
      "     |  \n",
      "     |  get_tags(self)\n",
      "     |      Get all current Task's tags.\n",
      "     |  \n",
      "     |  mark_completed(self, ignore_errors=True, status_message=None, force=False)\n",
      "     |      Use this method to close and change status of (remotely!) executed tasks.\n",
      "     |      \n",
      "     |      This method closes the task it is a member of,\n",
      "     |      changes its status to \"Completed\", and\n",
      "     |      terminates the Python process that created the task.\n",
      "     |      This is in contrast to :meth:`Task.close`, which does the first two steps, but does not terminate any Python process.\n",
      "     |      \n",
      "     |      Let's say that process A created the task and process B has a handle on the task, e.g., with :meth:`Task.get_task`.\n",
      "     |      Then, if we call :meth:`Task.mark_completed`, process A is terminated, but process B is not.\n",
      "     |      \n",
      "     |      However, if :meth:`Task.mark_completed` was called from the same process in which the task was created,\n",
      "     |      then - effectively - the process terminates itself.\n",
      "     |      For example, in\n",
      "     |      \n",
      "     |      .. code-block:: py\n",
      "     |      \n",
      "     |          task = Task.init(...)\n",
      "     |          task.mark_completed()\n",
      "     |          from time import sleep\n",
      "     |          sleep(30)\n",
      "     |          print('This text will not be printed!')\n",
      "     |      \n",
      "     |      the text will not be printed, because the Python process is immediately terminated.\n",
      "     |      \n",
      "     |      :param bool ignore_errors: If True (default), ignore any errors raised\n",
      "     |      :param bool force: If True, the task status will be changed to `stopped` regardless of the current Task state.\n",
      "     |      :param str status_message: Optional, add status change message to the stop request.\n",
      "     |          This message will be stored as status_message on the Task's info panel\n",
      "     |  \n",
      "     |  mark_failed(self, ignore_errors=True, status_reason=None, status_message=None, force=False)\n",
      "     |      The signal that this Task stopped.\n",
      "     |  \n",
      "     |  publish(self, ignore_errors=True)\n",
      "     |      The signal that this task will be published\n",
      "     |  \n",
      "     |  publish_on_completion(self, enable=True)\n",
      "     |      The signal that this task will be published automatically on task completion\n",
      "     |  \n",
      "     |  reload(self)\n",
      "     |      Reload current Task's state from clearml-server.\n",
      "     |      Refresh all task's fields, including artifacts / models / parameters etc.\n",
      "     |  \n",
      "     |  remove_input_models(self, models_to_remove)\n",
      "     |      Remove input models from the current task. Note that the models themselves are not deleted,\n",
      "     |      but the tasks' reference to the models is removed.\n",
      "     |      To delete the models themselves, see `Models.remove`\n",
      "     |      \n",
      "     |      :param models_to_remove: The models to remove from the task. Can be a list of ids,\n",
      "     |          or of `BaseModel` (including its subclasses: `Model` and `InputModel`)\n",
      "     |  \n",
      "     |  set_archived(self, archive)\n",
      "     |      Archive the Task or remove it from the archived folder.\n",
      "     |      \n",
      "     |      :param archive: If True, archive the Task. If False, make sure it is removed from the archived folder\n",
      "     |  \n",
      "     |  set_artifacts(self, artifacts_list=None)\n",
      "     |      List of artifacts (tasks.Artifact) to update the task\n",
      "     |      \n",
      "     |      :param list artifacts_list: list of artifacts (type tasks.Artifact)\n",
      "     |      :return: List of current Task's Artifacts or None if error.\n",
      "     |  \n",
      "     |  set_comment(self, comment)\n",
      "     |      Set a comment / description for the Task.\n",
      "     |      \n",
      "     |      :param comment: The comment / description for the Task.\n",
      "     |      :type comment: str\n",
      "     |  \n",
      "     |  set_configuration_object(self, name, config_text=None, description=None, config_type=None, config_dict=None)\n",
      "     |      Set the Task's configuration object as a blob of text or automatically encoded dictionary/list.\n",
      "     |      Use only for automation (externally), otherwise use `Task.connect_configuration`.\n",
      "     |      \n",
      "     |      :param str name: Configuration section name\n",
      "     |      :param config_text: configuration as a blob of text (unconstrained text string)\n",
      "     |          usually the content of a configuration file of a sort\n",
      "     |      :param str description: Configuration section description\n",
      "     |      :param str config_type: Optional configuration format type\n",
      "     |      :param dict config_dict: configuration dictionary/list to be encoded using HOCON (json alike) into stored text\n",
      "     |          Notice you can either pass `config_text` or `config_dict`, not both\n",
      "     |  \n",
      "     |  set_input_model(self, model_id=None, model_name=None, update_task_design=True, update_task_labels=True, name=None)\n",
      "     |      Set a new input model for the Task. The model must be \"ready\" (status is ``Published``) to be used as the\n",
      "     |      Task's input model.\n",
      "     |      \n",
      "     |      :param model_id: The ID of the model on the **ClearML Server** (backend). If ``model_name`` is not specified,\n",
      "     |          then ``model_id`` must be specified.\n",
      "     |      :param model_name: The model name in the artifactory. The model_name is used to locate an existing model\n",
      "     |          in the **ClearML Server** (backend). If ``model_id`` is not specified,\n",
      "     |          then ``model_name`` must be specified.\n",
      "     |      :param update_task_design: Update the Task's design\n",
      "     |      \n",
      "     |          - ``True`` - ClearML copies the Task's model design from the input model.\n",
      "     |          - ``False`` - ClearML does not copy the Task's model design from the input model.\n",
      "     |      \n",
      "     |      :param update_task_labels: Update the Task's label enumeration\n",
      "     |      \n",
      "     |          - ``True`` - ClearML copies the Task's label enumeration from the input model.\n",
      "     |          - ``False`` - ClearML does not copy the Task's label enumeration from the input model.\n",
      "     |      \n",
      "     |      :param name: Model section name to be stored on the Task (unrelated to the model object name itself)\n",
      "     |          Default: the model weight filename is used (excluding file extension)\n",
      "     |  \n",
      "     |  set_name(self, name)\n",
      "     |      Set the Task name.\n",
      "     |      \n",
      "     |      :param name: The name of the Task.\n",
      "     |      :type name: str\n",
      "     |  \n",
      "     |  set_parameter(self, name, value, description=None, value_type=None)\n",
      "     |      Set a single Task parameter. This overrides any previous value for this parameter.\n",
      "     |      \n",
      "     |      :param name: The parameter name.\n",
      "     |      :param value: The parameter value.\n",
      "     |      :param description: The parameter description.\n",
      "     |      :param value_type: The type of the parameters (cast to string and store)\n",
      "     |  \n",
      "     |  set_parameters(self, *args, **kwargs)\n",
      "     |      Set the parameters for a Task. This method sets a complete group of key-value parameter pairs, but does not\n",
      "     |      support parameter descriptions (the input is a dictionary of key-value pairs).\n",
      "     |      Notice the parameter dict is flat:\n",
      "     |      i.e. {'Args/param': 'value'} will set the argument \"param\" in section \"Args\" to \"value\"\n",
      "     |      \n",
      "     |      :param args: Positional arguments, which are one or more dictionaries or (key, value) iterable. They are\n",
      "     |          merged into a single key-value pair dictionary.\n",
      "     |      :param kwargs: Key-value pairs, merged into the parameters dictionary created from ``args``.\n",
      "     |  \n",
      "     |  set_parent(self, parent)\n",
      "     |      Set the parent task for the Task.\n",
      "     |      \n",
      "     |      :param parent: The parent task ID (or parent Task object) for the Task. Set None for no parent.\n",
      "     |      :type parent: str or Task\n",
      "     |  \n",
      "     |  set_project(self, project_id=None, project_name=None)\n",
      "     |      Set the project of the current task by either specifying a project name or ID\n",
      "     |  \n",
      "     |  set_system_tags(self, tags)\n",
      "     |  \n",
      "     |  set_tags(self, tags)\n",
      "     |      Set the current Task's tags. Please note this will overwrite anything that is there already.\n",
      "     |      \n",
      "     |      :param Sequence(str) tags: Any sequence of tags to set.\n",
      "     |  \n",
      "     |  set_task_type(self, task_type)\n",
      "     |      Set the task_type for the Task.\n",
      "     |      \n",
      "     |      :param task_type: The task_type of the Task.\n",
      "     |      \n",
      "     |          Valid task types:\n",
      "     |      \n",
      "     |          - ``TaskTypes.training``\n",
      "     |          - ``TaskTypes.testing``\n",
      "     |          - ``TaskTypes.inference``\n",
      "     |          - ``TaskTypes.data_processing``\n",
      "     |          - ``TaskTypes.application``\n",
      "     |          - ``TaskTypes.monitor``\n",
      "     |          - ``TaskTypes.controller``\n",
      "     |          - ``TaskTypes.optimizer``\n",
      "     |          - ``TaskTypes.service``\n",
      "     |          - ``TaskTypes.qc``\n",
      "     |          - ``TaskTypes.custom``\n",
      "     |      \n",
      "     |      :type task_type: str or TaskTypes\n",
      "     |  \n",
      "     |  started(self, ignore_errors=True, force=False)\n",
      "     |      The signal that this Task started.\n",
      "     |  \n",
      "     |  stopped(self, ignore_errors=True, force=False, status_reason=None, status_message=None)\n",
      "     |      The signal that this Task stopped.\n",
      "     |  \n",
      "     |  update_model_desc(self, new_model_desc_file=None)\n",
      "     |      Change the Task's model description.\n",
      "     |  \n",
      "     |  update_output_model(self, model_path, name=None, comment=None, tags=None, model_name=None, iteration=None, auto_delete_file=True)\n",
      "     |      Update the Task's output model weights file. First, ClearML uploads the file to the preconfigured output\n",
      "     |      destination (see the Task's ``output.destination`` property or call the ``setup_upload`` method),\n",
      "     |      then ClearML updates the model object associated with the Task. The API call uses the URI\n",
      "     |      of the uploaded file, and other values provided by additional arguments.\n",
      "     |      \n",
      "     |      Notice: A local model file will be uploaded to the task's `output_uri` destination,\n",
      "     |      If no `output_uri` was specified, the default files-server will be used to store the model file/s.\n",
      "     |      \n",
      "     |      :param model_path: A local weights file or folder to be uploaded.\n",
      "     |          If remote URI is provided (e.g. http:// or s3: // etc) then the URI is stored as is, without any upload\n",
      "     |      :param name: The updated model name.\n",
      "     |          If not provided, the name is the model weights file filename without the extension.\n",
      "     |      :param comment: The updated model description. (Optional)\n",
      "     |      :param tags: The updated model tags. (Optional)\n",
      "     |      :param model_name: If provided the model name as it will appear in the model artifactory. (Optional)\n",
      "     |          Default: Task.name - name\n",
      "     |      :param iteration: iteration number for the current stored model (Optional)\n",
      "     |      :param bool auto_delete_file: Delete the temporary file after uploading (Optional)\n",
      "     |      \n",
      "     |          - ``True`` - Delete (Default)\n",
      "     |          - ``False`` - Do not delete\n",
      "     |      \n",
      "     |      :return: The URI of the uploaded weights file.\n",
      "     |          Notice: upload is done is a background thread, while the function call returns immediately\n",
      "     |  \n",
      "     |  update_parameters(self, *args, **kwargs)\n",
      "     |      Update the parameters for a Task. This method updates a complete group of key-value parameter pairs, but does\n",
      "     |      not support parameter descriptions (the input is a dictionary of key-value pairs).\n",
      "     |      Notice the parameter dict is flat:\n",
      "     |      i.e. {'Args/param': 'value'} will set the argument \"param\" in section \"Args\" to \"value\"\n",
      "     |      \n",
      "     |      :param args: Positional arguments, which are one or more dictionaries or (key, value) iterable. They are\n",
      "     |          merged into a single key-value pair dictionary.\n",
      "     |      :param kwargs: Key-value pairs, merged into the parameters dictionary created from ``args``.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from clearml.backend_interface.task.task.Task:\n",
      "     |  \n",
      "     |  add_requirements(package_name, package_version=None) from abc.ABCMeta\n",
      "     |      Force the adding of a package to the requirements list. If ``package_version`` is None, use the\n",
      "     |      installed package version, if found.\n",
      "     |      Example: Task.add_requirements('tensorflow', '2.4.0')\n",
      "     |      Example: Task.add_requirements('tensorflow', '>=2.4')\n",
      "     |      Example: Task.add_requirements('tensorflow') -> use the installed tensorflow version\n",
      "     |      Example: Task.add_requirements('tensorflow', '') -> no version limit\n",
      "     |      Alternatively, you can add all requirements from a file.\n",
      "     |      Example: Task.add_requirements('/path/to/your/project/requirements.txt')\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          Task.add_requirements does not directly modify the task's requirements. Instead, it improves the accuracy\n",
      "     |          of capturing a task's Python packages. To explicitly change task requirements, use\n",
      "     |          Task.set_packages, which overwrites existing packages with the specified ones.\n",
      "     |      \n",
      "     |      :param str package_name: The package name or path to a requirements file\n",
      "     |          to add to the \"Installed Packages\" section of the task.\n",
      "     |      :param package_version: The package version requirements. If ``None``, then  use the installed version.\n",
      "     |  \n",
      "     |  force_requirements_env_freeze(force=True, requirements_file=None) from abc.ABCMeta\n",
      "     |      Force the use of ``pip freeze`` or ``conda list`` to capture the requirements from the active\n",
      "     |      environment (instead of statically analyzing the running code and listing directly imported packages).\n",
      "     |      Notice: Must be called before `Task.init` !\n",
      "     |      \n",
      "     |      :param force: If ``True`` (default), force the use of ``pip freeze`` or ``conda list`` to capture the\n",
      "     |          requirements. If ``False``, ClearML statistically analyzes the code for requirements.\n",
      "     |      :param requirements_file: (Optional) Pass a requirements.txt file to specify the required packages (instead of\n",
      "     |          ``pip freeze`` or automatic analysis). This will overwrite any existing requirement listing.\n",
      "     |  \n",
      "     |  force_store_standalone_script(force=True) from abc.ABCMeta\n",
      "     |      Force using storing the main python file as a single standalone script, instead of linking with the\n",
      "     |      local git repository/commit ID.\n",
      "     |      \n",
      "     |      Notice: Must be called before `Task.init` !\n",
      "     |      \n",
      "     |      :param force: Set force storing the main python file as a single standalone script\n",
      "     |  \n",
      "     |  get_all(session=None, log=None, **kwargs) from abc.ABCMeta\n",
      "     |      List all the Tasks based on specific projection.\n",
      "     |      \n",
      "     |      :param Session session: The session object used for sending requests to the API.\n",
      "     |      :param logging.Logger log: The Log object.\n",
      "     |      :param kwargs: Keyword args passed to the GetAllRequest\n",
      "     |          (see :class:`.backend_api.service.v?.tasks.GetAllRequest` for details; the ? needs to be replaced by the appropriate version.)\n",
      "     |      \n",
      "     |          For example:\n",
      "     |      \n",
      "     |          .. code-block:: bash\n",
      "     |      \n",
      "     |             status='completed', 'search_text'='specific_word', 'user'='user_id', 'project'='project_id'\n",
      "     |      \n",
      "     |      :type kwargs: dict\n",
      "     |      \n",
      "     |      :return: The API response.\n",
      "     |  \n",
      "     |  get_project_id(project_name, search_hidden=True) from abc.ABCMeta\n",
      "     |      Return a project's unique ID (str).\n",
      "     |      If more than one project matched the project_name, return the last updated project\n",
      "     |      If no project matched the requested name, returns None\n",
      "     |      \n",
      "     |      :return: Project unique ID (str), or None if no project was found.\n",
      "     |  \n",
      "     |  get_projects(**kwargs) from abc.ABCMeta\n",
      "     |      Return a list of projects in the system, sorted by last updated time\n",
      "     |      \n",
      "     |      :return: A list of all the projects in the system. Each entry is a `services.projects.Project` object.\n",
      "     |  \n",
      "     |  get_task_output_log_web_page(task_id, project_id=None, app_server_host=None) from abc.ABCMeta\n",
      "     |      Return the Task results & outputs web page address.\n",
      "     |      For example: https://demoapp.demo.clear.ml/projects/216431/experiments/60763e04/output/log\n",
      "     |      \n",
      "     |      :param str task_id: Task ID.\n",
      "     |      :param str project_id: Project ID for this task.\n",
      "     |      :param str app_server_host: ClearML Application server host name.\n",
      "     |          If not provided, the current session will be used to resolve the host name.\n",
      "     |      :return: http/s URL link.\n",
      "     |  \n",
      "     |  ignore_requirements(package_name) from abc.ABCMeta\n",
      "     |      Ignore a specific package when auto generating the requirements list.\n",
      "     |      Example: Task.ignore_requirements('pywin32')\n",
      "     |      \n",
      "     |      :param str package_name: The package name to remove/ignore from the \"Installed Packages\" section of the task.\n",
      "     |  \n",
      "     |  set_random_seed(random_seed) from abc.ABCMeta\n",
      "     |      Set the default random seed for any new initialized tasks\n",
      "     |      \n",
      "     |      :param random_seed: If None or False, disable random seed initialization. If True, use the default random seed,\n",
      "     |        otherwise use the provided int value for random seed initialization when initializing a new task.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from clearml.backend_interface.task.task.Task:\n",
      "     |  \n",
      "     |  running_locally()\n",
      "     |      Is the task running locally (i.e., ``clearml-agent`` is not executing it)\n",
      "     |      \n",
      "     |      :return: True, if the task is running locally. False, if the task is not running locally.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from clearml.backend_interface.task.task.Task:\n",
      "     |  \n",
      "     |  cache_dir\n",
      "     |      The cache directory which is used to store the Task related files.\n",
      "     |  \n",
      "     |  input_models_id\n",
      "     |      Returns the current Task's input model IDs as a dictionary.\n",
      "     |  \n",
      "     |  labels_stats\n",
      "     |      Get accumulated label stats for the current/last frames iteration\n",
      "     |  \n",
      "     |  metrics_manager\n",
      "     |      A metrics manager used to manage the metrics related to this task\n",
      "     |  \n",
      "     |  output_models_id\n",
      "     |      Returns the current Task's output model IDs as a dictionary.\n",
      "     |  \n",
      "     |  parent\n",
      "     |      Returns the current Task's parent task ID (str).\n",
      "     |  \n",
      "     |  project\n",
      "     |      Returns the current Task's project ID.\n",
      "     |  \n",
      "     |  status\n",
      "     |      The Task's status. To keep the Task updated.\n",
      "     |      ClearML reloads the Task status information only, when this value is accessed.\n",
      "     |      \n",
      "     |      return str: TaskStatusEnum status\n",
      "     |  \n",
      "     |  task_id\n",
      "     |      Returns the current Task's ID.\n",
      "     |  \n",
      "     |  task_type\n",
      "     |      Returns the current Task's type.\n",
      "     |      \n",
      "     |          Valid task types:\n",
      "     |      \n",
      "     |          - ``TaskTypes.training`` (default)\n",
      "     |          - ``TaskTypes.testing``\n",
      "     |          - ``TaskTypes.inference``\n",
      "     |          - ``TaskTypes.data_processing``\n",
      "     |          - ``TaskTypes.application``\n",
      "     |          - ``TaskTypes.monitor``\n",
      "     |          - ``TaskTypes.controller``\n",
      "     |          - ``TaskTypes.optimizer``\n",
      "     |          - ``TaskTypes.service``\n",
      "     |          - ``TaskTypes.qc``\n",
      "     |          - ``TaskTypes.custom``\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from clearml.backend_interface.task.task.Task:\n",
      "     |  \n",
      "     |  comment\n",
      "     |      Returns the current Task's (user defined) comments.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the current Task's name.\n",
      "     |  \n",
      "     |  storage_uri\n",
      "     |      The storage / output url for this task. This is the default location for output models and other artifacts.\n",
      "     |      \n",
      "     |      :return: The url string or None if not set.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from clearml.backend_interface.task.task.Task:\n",
      "     |  \n",
      "     |  DeleteError = <class 'clearml.backend_interface.task.task.Task.DeleteE...\n",
      "     |  \n",
      "     |  TaskStatusEnum = <enum 'TaskStatusEnum'>\n",
      "     |      An enumeration.\n",
      "     |  \n",
      "     |  \n",
      "     |  archived_tag = 'archived'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from clearml.backend_interface.base.IdObjectBase:\n",
      "     |  \n",
      "     |  normalize_id(id) from abc.ABCMeta\n",
      "     |  \n",
      "     |  resolve_id(obj) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from clearml.backend_interface.base.IdObjectBase:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from clearml.backend_interface.base.IdObjectBase:\n",
      "     |  \n",
      "     |  id\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from clearml.backend_interface.base.InterfaceBase:\n",
      "     |  \n",
      "     |  send(self, req, ignore_errors=False, raise_on_errors=True, async_enable=False)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from clearml.backend_interface.base.InterfaceBase:\n",
      "     |  \n",
      "     |  default_session\n",
      "     |  \n",
      "     |  log\n",
      "     |  \n",
      "     |  session\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from clearml.backend_interface.session.SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from clearml.backend_interface.task.access.AccessMixin:\n",
      "     |  \n",
      "     |  get_label_num_description(self)\n",
      "     |      Get a dictionary of label number to string pairs representing all labels associated with this number\n",
      "     |      on the model labels.\n",
      "     |  \n",
      "     |  get_num_of_classes(self)\n",
      "     |      number of classes based on the task's labels\n",
      "     |  \n",
      "     |  get_output_destination(self, extra_path=None, **kwargs)\n",
      "     |      Get the task's output destination, with an optional suffix\n",
      "     |  \n",
      "     |  save_exec_model_design_file(self, filename='model_design.txt', use_cache=False)\n",
      "     |      Save execution model design to file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from clearml.backend_interface.setupuploadmixin.SetupUploadMixin:\n",
      "     |  \n",
      "     |  setup_aws_upload(self, bucket, subdir=None, host=None, key=None, secret=None, token=None, region=None, multipart=True, secure=True, verify=True, profile=None)\n",
      "     |      Setup S3 upload options.\n",
      "     |      \n",
      "     |      :param bucket: AWS bucket name\n",
      "     |      :param subdir: Subdirectory in the AWS bucket\n",
      "     |      :param host: Hostname. Only required in case a Non-AWS S3 solution such as a local Minio server is used)\n",
      "     |      :param key: AWS access key. If not provided, we'll attempt to obtain the key from the\n",
      "     |          configuration file (bucket-specific, than global)\n",
      "     |      :param secret: AWS secret key. If not provided, we'll attempt to obtain the secret from the\n",
      "     |          configuration file (bucket-specific, than global)\n",
      "     |      :param token: AWS 2FA token\n",
      "     |      :param region: Bucket region. Required if the bucket doesn't reside in the default region (us-east-1)\n",
      "     |      :param multipart: Server supports multipart. Only required when using a Non-AWS S3 solution that doesn't support\n",
      "     |          multipart.\n",
      "     |      :param secure: Server supports HTTPS. Only required when using a Non-AWS S3 solution that only supports HTTPS.\n",
      "     |      :param verify: Whether or not to verify SSL certificates.\n",
      "     |      :param profile: The AWS profile\n",
      "     |          Only required when using a Non-AWS S3 solution that only supports HTTPS with self-signed certificate.\n",
      "     |  \n",
      "     |  setup_azure_upload(self, account_name, account_key, container_name=None)\n",
      "     |      Setup Azure upload options.\n",
      "     |      \n",
      "     |      :param account_name: Name of the account\n",
      "     |      :param account_key: Secret key used to authenticate the account\n",
      "     |      :param container_name: The name of the blob container to upload to\n",
      "     |  \n",
      "     |  setup_gcp_upload(self, bucket, subdir='', project=None, credentials_json=None, pool_connections=None, pool_maxsize=None)\n",
      "     |      Setup GCP upload options.\n",
      "     |      \n",
      "     |      :param bucket: Bucket to upload to\n",
      "     |      :param subdir: Subdir in bucket to upload to\n",
      "     |      :param project: Project the bucket belongs to\n",
      "     |      :param credentials_json: Path to the JSON file that contains the credentials\n",
      "     |      :param pool_connections: The number of urllib3 connection pools to cache\n",
      "     |      :param pool_maxsize: The maximum number of connections to save in the pool\n",
      "     |  \n",
      "     |  setup_upload(self, bucket_name, host=None, access_key=None, secret_key=None, multipart=True, https=True, region=None, verify=True)\n",
      "     |      (Deprecated) Setup upload options. Only S3 is supported.\n",
      "     |      Please note that this function is deprecated. Use `setup_aws_upload`, `setup_gcp_upload` or\n",
      "     |      `setup_azure_upload` to setup the upload options for the corresponding cloud.\n",
      "     |      \n",
      "     |      :param bucket_name: AWS bucket name\n",
      "     |      :param host: Hostname. Only required in case a Non-AWS S3 solution such as a local Minio server is used)\n",
      "     |      :param access_key: AWS access key. If not provided, we'll attempt to obtain the key from the\n",
      "     |          configuration file (bucket-specific, than global)\n",
      "     |      :param secret_key: AWS secret key. If not provided, we'll attempt to obtain the secret from the\n",
      "     |          configuration file (bucket-specific, than global)\n",
      "     |      :param multipart: Server supports multipart. Only required when using a Non-AWS S3 solution that doesn't support\n",
      "     |          multipart.\n",
      "     |      :param https: Server supports HTTPS. Only required when using a Non-AWS S3 solution that only supports HTTPS.\n",
      "     |      :param region: Bucket region. Required if the bucket doesn't reside in the default region (us-east-1)\n",
      "     |      :param verify: Whether or not to verify SSL certificates.\n",
      "     |          Only required when using a Non-AWS S3 solution that only supports HTTPS with self-signed certificate.\n",
      "\n",
      "DATA\n",
      "    Any = typing.Any\n",
      "        Special type indicating an unconstrained type.\n",
      "        \n",
      "        - Any is compatible with every type.\n",
      "        - Any assumed to have all methods.\n",
      "        - All values assumed to be instances of Any.\n",
      "        \n",
      "        Note that all the above statements are true from the point of view of\n",
      "        static type checkers. At runtime, Any should not be used with instance\n",
      "        or class checks.\n",
      "    \n",
      "    Callable = typing.Callable\n",
      "        Callable type; Callable[[int], str] is a function of (int) -> str.\n",
      "        \n",
      "        The subscription syntax must always be used with exactly two\n",
      "        values: the argument list and the return type.  The argument list\n",
      "        must be a list of types or ellipsis; the return type must be a single type.\n",
      "        \n",
      "        There is no syntax to indicate optional or keyword arguments,\n",
      "        such function types are rarely used as callback types.\n",
      "    \n",
      "    DEBUG_SIMULATE_REMOTE_TASK = <clearml.backend_config.environment.EnvEn...\n",
      "    DEV_DEFAULT_OUTPUT_URI = <clearml.backend_config.environment.EnvEntry ...\n",
      "    DEV_TASK_NO_REUSE = <clearml.backend_config.environment.EnvEntry objec...\n",
      "    Dict = typing.Dict\n",
      "        A generic version of dict.\n",
      "    \n",
      "    ENV_ACCESS_KEY = <clearml.backend_config.environment.EnvEntry object>\n",
      "    ENV_DEFERRED_TASK_INIT = <clearml.backend_config.environment.EnvEntry ...\n",
      "    ENV_FILES_HOST = <clearml.backend_config.environment.EnvEntry object>\n",
      "    ENV_HOST = <clearml.backend_config.environment.EnvEntry object>\n",
      "    ENV_IGNORE_MISSING_CONFIG = <clearml.backend_config.environment.EnvEnt...\n",
      "    ENV_OFFLINE_MODE = <clearml.backend_config.environment.EnvEntry object...\n",
      "    ENV_SECRET_KEY = <clearml.backend_config.environment.EnvEntry object>\n",
      "    ENV_WEB_HOST = <clearml.backend_config.environment.EnvEntry object>\n",
      "    Iterable = typing.Iterable\n",
      "        A generic version of collections.abc.Iterable.\n",
      "    \n",
      "    List = typing.List\n",
      "        A generic version of list.\n",
      "    \n",
      "    Mapping = typing.Mapping\n",
      "        A generic version of collections.abc.Mapping.\n",
      "    \n",
      "    Optional = typing.Optional\n",
      "        Optional type.\n",
      "        \n",
      "        Optional[X] is equivalent to Union[X, None].\n",
      "    \n",
      "    Sequence = typing.Sequence\n",
      "        A generic version of collections.abc.Sequence.\n",
      "    \n",
      "    TASK_SET_ITERATION_OFFSET = <clearml.backend_config.environment.EnvEnt...\n",
      "    TYPE_CHECKING = False\n",
      "    TaskInstance = ~TaskInstance\n",
      "    Tuple = typing.Tuple\n",
      "        Tuple type; Tuple[X, Y] is the cross-product type of X and Y.\n",
      "        \n",
      "        Example: Tuple[T1, T2] is a tuple of two elements corresponding\n",
      "        to type variables T1 and T2.  Tuple[int, float, str] is a tuple\n",
      "        of an int, a float and a string.\n",
      "        \n",
      "        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].\n",
      "    \n",
      "    Union = typing.Union\n",
      "        Union type; Union[X, Y] means either X or Y.\n",
      "        \n",
      "        To define a union, use e.g. Union[int, str].  Details:\n",
      "        - The arguments must be types and there must be at least one.\n",
      "        - None as an argument is a special case and is replaced by\n",
      "          type(None).\n",
      "        - Unions of unions are flattened, e.g.::\n",
      "        \n",
      "            Union[Union[int, str], float] == Union[int, str, float]\n",
      "        \n",
      "        - Unions of a single argument vanish, e.g.::\n",
      "        \n",
      "            Union[int] == int  # The constructor actually returns int\n",
      "        \n",
      "        - Redundant arguments are skipped, e.g.::\n",
      "        \n",
      "            Union[int, str, int] == Union[int, str]\n",
      "        \n",
      "        - When comparing unions, the argument order is ignored, e.g.::\n",
      "        \n",
      "            Union[int, str] == Union[str, int]\n",
      "        \n",
      "        - You cannot subclass or instantiate a union.\n",
      "        - You can use Optional[X] as a shorthand for Union[X, None].\n",
      "    \n",
      "    ZIP_DEFLATED = 8\n",
      "    events = <clearml.backend_api.api_proxy.ApiServiceProxy object>\n",
      "    projects = <clearml.backend_api.api_proxy.ApiServiceProxy object>\n",
      "    tasks = <clearml.backend_api.api_proxy.ApiServiceProxy object>\n",
      "\n",
      "FILE\n",
      "    c:\\users\\janfi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages\\clearml\\task.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Example submodule to inspect\n",
    "submodule_name = \"clearml.task\"\n",
    "\n",
    "# Dynamically import the submodule\n",
    "submodule = importlib.import_module(submodule_name)\n",
    "\n",
    "# Use dir() to list the attributes and methods of the submodule\n",
    "print(f\"Attributes and methods in {submodule_name}:\")\n",
    "print(dir(submodule))\n",
    "\n",
    "# Use help() to get more detailed information\n",
    "print(f\"\\nDetailed information about {submodule_name}:\")\n",
    "help(submodule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
